{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1de0b649-ca31-4f0f-a2c6-e5ae3f81db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andrewreusche/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import relevant libraries\n",
    "\n",
    "#general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import FreqDist, pos_tag\n",
    "\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#model evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#preprocessing and pipleline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#imbalanced data\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a53219-1d95-4b4e-9bf9-c553f0332e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df525da-5f8a-4761-b2c3-dd9701caa22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('data/judge-1377884607_tweet_product_company.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a5292c-2893-4aba-902d-8e41bdcab4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356e19b0-176d-4f1e-aeda-db84dd5ff959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "No emotion toward brand or product    0.592613\n",
       "Positive emotion                      0.327453\n",
       "Negative emotion                      0.062734\n",
       "I can't tell                          0.017200\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df= df[['tweet_text','is_there_an_emotion_directed_at_a_brand_or_product']]\n",
    "raw_df= raw_df.dropna()\n",
    "raw_df = raw_df.drop_duplicates(keep='first')\n",
    "raw_df = raw_df.rename(columns={'tweet_text': 'tweet', \n",
    "                                'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'})\n",
    "raw_df['emotion'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af86719e-4a30-48dc-8878-b087f1524ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    0.666816\n",
       "1    0.333184\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_raw_df = raw_df[raw_df['emotion'] != \"I can't tell\"]\n",
    "sentiment_map = {'No emotion toward brand or product': 0,\n",
    "    'Positive emotion': 1,\n",
    "    'Negative emotion': 0}\n",
    "rel_raw_df['sentiment'] = rel_raw_df['emotion'].map(sentiment_map)\n",
    "rel_raw_df['sentiment'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e19b7-f472-4bf9-b2e1-451e92f208de",
   "metadata": {},
   "source": [
    "rel_raw_df['tweet'][9088]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f7e5244-8893-4901-89f0-db7771b4db9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 new ipad apps for #speechtherapy...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#sxsw is just starting, #ctia is around the co...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beautifully smart and simple idea rt @madebyma...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>counting down the days to #sxsw plus strong ca...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "0   .@wesley83 i have a 3g iphone. after 3 hrs twe...   \n",
       "1   @jessedee know about @fludapp ? awesome ipad/i...   \n",
       "2   @swonderlin can not wait for #ipad 2 also. the...   \n",
       "3   @sxsw i hope this year's festival isn't as cra...   \n",
       "4   @sxtxstate great stuff on fri #sxsw: marissa m...   \n",
       "5   @teachntech00 new ipad apps for #speechtherapy...   \n",
       "7   #sxsw is just starting, #ctia is around the co...   \n",
       "8   beautifully smart and simple idea rt @madebyma...   \n",
       "9   counting down the days to #sxsw plus strong ca...   \n",
       "10  excited to meet the @samsungmobileus at #sxsw ...   \n",
       "\n",
       "                               emotion  sentiment  \n",
       "0                     Negative emotion          0  \n",
       "1                     Positive emotion          1  \n",
       "2                     Positive emotion          1  \n",
       "3                     Negative emotion          0  \n",
       "4                     Positive emotion          1  \n",
       "5   No emotion toward brand or product          0  \n",
       "7                     Positive emotion          1  \n",
       "8                     Positive emotion          1  \n",
       "9                     Positive emotion          1  \n",
       "10                    Positive emotion          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_raw_df[\"tweet\"] = rel_raw_df[\"tweet\"].str.lower()\n",
    "rel_raw_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a234f-36ab-403f-a958-dff75c2097b2",
   "metadata": {},
   "source": [
    "word_tokenize('hello i am mark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fb22bd-b9f5-4eae-8f84-72bf8fdab91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9092 is a nonsensical symbolized tweet, drop it\n",
    "rel_raw_df= rel_raw_df.drop(9092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b447c71-b5d2-4309-a9ff-704c1e83c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have a 3g iphone. after 3 hrs tweeting at it...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, have, a, iphone, after, hrs, tweeting, at,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know about ? awesome ipad/iphone app that you'...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, about, awesome, ipad, iphone, app, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can not wait for 2 also. they should sale them...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[cant, wait, for, also, they, should, sale, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hope this year's festival isn't as crashy as...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, hope, this, years, festival, isnt, as, cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stuff on fri marissa mayer (google), tim...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, stuff, on, fri, marissa, mayer, google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>yup, but i don't have a third app yet. i'm on ...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[yup, but, i, dont, have, a, third, app, yet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>ipad everywhere. {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[ipad, everywhere, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>wave, buzz... rt we interrupt your regularly s...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[wave, buzz, rt, we, interrupt, your, regularl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>google's zeiger, a physician never reported po...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[googles, zeiger, a, physician, never, reporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>some verizon iphone customers complained their...</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[some, verizon, iphone, customers, complained,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "0     i have a 3g iphone. after 3 hrs tweeting at it...   \n",
       "1     know about ? awesome ipad/iphone app that you'...   \n",
       "2     can not wait for 2 also. they should sale them...   \n",
       "3     i hope this year's festival isn't as crashy as...   \n",
       "4     great stuff on fri marissa mayer (google), tim...   \n",
       "...                                                 ...   \n",
       "9087  yup, but i don't have a third app yet. i'm on ...   \n",
       "9088                            ipad everywhere. {link}   \n",
       "9089  wave, buzz... rt we interrupt your regularly s...   \n",
       "9090  google's zeiger, a physician never reported po...   \n",
       "9091  some verizon iphone customers complained their...   \n",
       "\n",
       "                                 emotion  sentiment  \\\n",
       "0                       Negative emotion          0   \n",
       "1                       Positive emotion          1   \n",
       "2                       Positive emotion          1   \n",
       "3                       Negative emotion          0   \n",
       "4                       Positive emotion          1   \n",
       "...                                  ...        ...   \n",
       "9087  No emotion toward brand or product          0   \n",
       "9088                    Positive emotion          1   \n",
       "9089  No emotion toward brand or product          0   \n",
       "9090  No emotion toward brand or product          0   \n",
       "9091  No emotion toward brand or product          0   \n",
       "\n",
       "                                        tweet_tokenized  \n",
       "0     [i, have, a, iphone, after, hrs, tweeting, at,...  \n",
       "1     [know, about, awesome, ipad, iphone, app, that...  \n",
       "2     [cant, wait, for, also, they, should, sale, th...  \n",
       "3     [i, hope, this, years, festival, isnt, as, cra...  \n",
       "4     [great, stuff, on, fri, marissa, mayer, google...  \n",
       "...                                                 ...  \n",
       "9087  [yup, but, i, dont, have, a, third, app, yet, ...  \n",
       "9088                           [ipad, everywhere, link]  \n",
       "9089  [wave, buzz, rt, we, interrupt, your, regularl...  \n",
       "9090  [googles, zeiger, a, physician, never, reporte...  \n",
       "9091  [some, verizon, iphone, customers, complained,...  \n",
       "\n",
       "[8913 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing usernames\n",
    "rel_raw_df[\"tweet\"]= rel_raw_df[\"tweet\"].apply(lambda x : ' '.join(\n",
    "    [w for w in x.split() if '@' not in w]).strip())\n",
    "\n",
    "#removing hashtags\n",
    "rel_raw_df[\"tweet\"]= rel_raw_df[\"tweet\"].apply(lambda x : ' '.join(\n",
    "    [w for w in x.split() if '#' not in w]))\n",
    "\n",
    "#use ReGex to strip the tweets down to only what we want\n",
    "def strip_token(tweet):\n",
    "    tweet = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', tweet) #remove all links form tweets\n",
    "    tweet = re.sub(r'&amp;', 'and', tweet) #convert all instances of '&amp' to 'and'\n",
    "    tweet = re.sub(r\"'\", \"\", tweet) #removes \" ' \" converting \"can't\" to \"cant\"\n",
    "    tweet = re.sub(r'_', ' ', tweet) #removes all '_' from tweets\n",
    "    tweet = re.sub(r'[^\\w\\s]', ' ', tweet) #removes all non word characters from tweets\n",
    "    tweet = re.sub(r'\\d+\\w*', '', tweet) #removes all numbers or character combinations that begin with numbers \n",
    "    tweet = re.sub(r'can not', \"cant\", tweet) #convert all instances of 'can not' to 'cant'\n",
    "    tweet = re.sub(r'will not', \"wont\", tweet) #convert all instances of 'will not' to 'wont'\n",
    "    tweet = re.sub(r'do not', \"dont\", tweet) #convert all instances of 'do not' to 'dont'\n",
    "    tweet = re.sub(r'\\b[^a-zA-Z]+', ' ', tweet) #should strip all non standard a-z characters left over \n",
    "    tokens = word_tokenize(tweet)\n",
    "    return tokens\n",
    "rel_raw_df['tweet_tokenized'] = rel_raw_df['tweet'].apply(strip_token)\n",
    "\n",
    "#preview dataset\n",
    "rel_raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f3ca2-75d9-420a-94cc-36ac102c4610",
   "metadata": {},
   "source": [
    "#this column is just a test\n",
    "\n",
    "monkey=' _ the big_monkey / throws a yellow/bannana _/far'\n",
    "\n",
    "#use ReGex to strip the tweets down to only what we want\n",
    "def strip_token2(tweet):\n",
    "    tweet = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', tweet) #remove all links form tweets\n",
    "    tweet = re.sub(r'&amp;', 'and', tweet) #convert all instances of '&amp' to 'and'\n",
    "    #tweet = re.sub(r'/', ' ', tweet) #removes all '/' from tweets\n",
    "    tweet = re.sub(r'_', ' ', tweet) #removes all '_' from tweets\n",
    "    tweet = re.sub(r'[^\\w\\s]', ' ', tweet) #removes all non word characters from tweets\n",
    "    tweet = re.sub(r'\\d+\\w*', '', tweet) #removes all numbers or character combinations that begin with numbers \n",
    "    tweet = re.sub(r'can not', \"cant\", tweet) #convert all instances of 'can not' to 'cant'\n",
    "    tweet = re.sub(r'will not', \"wont\", tweet) #convert all instances of 'will not' to 'wont'\n",
    "    tweet = re.sub(r'do not', \"dont\", tweet) #convert all instances of 'do not' to 'dont'\n",
    "    tokens = word_tokenize(tweet)\n",
    "    return tokens\n",
    "\n",
    "monkey2= strip_token2(monkey)\n",
    "\n",
    "print(monkey2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbed7a77-aa0f-428d-8b72-c0d12bd971ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>great ipad app from http://tinyurl.com/4nqv92l</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, ipad, app, from]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>÷¼ what? ÷_ {link} ã_</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, link]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>i worship {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, worship, link]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>stay tune showcase {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[stay, tune, showcase, link]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>follow lead {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[follow, lead, link]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>well put. totally agree!</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[well, put, totally, agree]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>black or white ipad?</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[black, or, white, ipad]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>google arwords, arsense anyone?</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[google, arwords, arsense, anyone]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>... or maybe not: {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[or, maybe, not, link]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>ipad everywhere. {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[ipad, everywhere, link]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "14    great ipad app from http://tinyurl.com/4nqv92l   \n",
       "52                          ÷¼ what? ÷_ {link} ã_   \n",
       "77                                  i worship {link}   \n",
       "85                         stay tune showcase {link}   \n",
       "133                               follow lead {link}   \n",
       "...                                              ...   \n",
       "8885                        well put. totally agree!   \n",
       "8904                            black or white ipad?   \n",
       "8923                 google arwords, arsense anyone?   \n",
       "9031                        ... or maybe not: {link}   \n",
       "9088                         ipad everywhere. {link}   \n",
       "\n",
       "                                 emotion  sentiment  \\\n",
       "14                      Positive emotion          1   \n",
       "52    No emotion toward brand or product          0   \n",
       "77    No emotion toward brand or product          0   \n",
       "85    No emotion toward brand or product          0   \n",
       "133   No emotion toward brand or product          0   \n",
       "...                                  ...        ...   \n",
       "8885  No emotion toward brand or product          0   \n",
       "8904  No emotion toward brand or product          0   \n",
       "8923  No emotion toward brand or product          0   \n",
       "9031  No emotion toward brand or product          0   \n",
       "9088                    Positive emotion          1   \n",
       "\n",
       "                         tweet_tokenized  tweet_len  \n",
       "14              [great, ipad, app, from]          4  \n",
       "52                          [what, link]          2  \n",
       "77                    [i, worship, link]          3  \n",
       "85          [stay, tune, showcase, link]          4  \n",
       "133                 [follow, lead, link]          3  \n",
       "...                                  ...        ...  \n",
       "8885         [well, put, totally, agree]          4  \n",
       "8904            [black, or, white, ipad]          4  \n",
       "8923  [google, arwords, arsense, anyone]          4  \n",
       "9031              [or, maybe, not, link]          4  \n",
       "9088            [ipad, everywhere, link]          3  \n",
       "\n",
       "[86 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column to show how long the tweets are, shorter \n",
    "rel_raw_df['tweet_len']= rel_raw_df.tweet_tokenized.apply(lambda x : len(x))\n",
    "#consider getting rid of all tweets that are less than 5 characters long\n",
    "rel_raw_df[rel_raw_df['tweet_len']<5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543438af-95c2-4e6a-9c2e-66ac785cb0db",
   "metadata": {},
   "source": [
    "stopwords_list= stopwords.words('english')\n",
    "stopwords_list = [word for word in stopwords_list if word not in ['not', 'can']]\n",
    "#possibly append words to the list of stop words\n",
    "#additional_stopwords= ['google', 'iphone', 'ipad', 'link', 'apple', 'rt', 'store', 'quot', 'austin', 'via', 'sxsw']\n",
    "#stopwords_list.append('additional_stopwords')\n",
    "\n",
    "def remove_stopwords(token_list):\n",
    "    list_stripped= [x for x in token_list if x not in stopwords_list]\n",
    "    return list_stripped\n",
    "\n",
    "rel_raw_df['tweet_tokenized_ns'] = rel_raw_df['tweet_tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e7991-52f2-49d6-b719-4571063b72b4",
   "metadata": {},
   "source": [
    "rel_raw_df[\"tweet_tokenized_ns\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fba4c-b2e6-47cc-8d36-d640131c331d",
   "metadata": {},
   "source": [
    "rel_raw_df[\"tweet_tokenized_ns\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54bb32f-0aa3-4abc-b9f2-d0d0d5e61a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmetize the tokens\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lem_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "rel_raw_df['tweet_lem'] = rel_raw_df['tweet_tokenized'].apply(lem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eefd2ea9-9e48-4c73-b89b-ceb0a0168329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersample here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f34058f-8d6b-4e99-922b-1338344ae894",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= rel_raw_df['tweet_lem']\n",
    "y= rel_raw_df['sentiment']\n",
    "\n",
    "#Train split (remain is the remaining data)\n",
    "X_train, X_remain, y_train, y_remain= train_test_split(X, y, \n",
    "                                                   test_size= 0.2,  \n",
    "                                                   random_state= 24)\n",
    "\n",
    "#Val test split \n",
    "X_val, X_test, y_val, y_test= train_test_split(X_remain, y_remain,\n",
    "                                               test_size= 0.5, \n",
    "                                               random_state= 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f0eac1-6aef-4ea0-bda0-ad1bb20cce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out the word distrobutions in X_train for each target class\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "color_palette = sns.color_palette('cividis', n_colors=38)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(12, 12)) \n",
    "\n",
    "plotted_words_and_colors = {}\n",
    "\n",
    "sentiment_classes = y_train.unique() \n",
    "for i, sentiment_class in enumerate(sentiment_classes):\n",
    "    sentiment_data = X_train[y_train == sentiment_class]\n",
    "    all_words_in_sentiment = [word for tokens in sentiment_data for word in tokens]\n",
    "    top_10 = Counter(all_words_in_sentiment).most_common(20)\n",
    "    \n",
    "    colors = []\n",
    "    \n",
    "    for word, _ in top_10:\n",
    "        if word not in plotted_words_and_colors:\n",
    "            new_color = color_palette.pop(0)\n",
    "            plotted_words_and_colors[word] = new_color\n",
    "        colors.append(plotted_words_and_colors[word])\n",
    "    \n",
    "    ax = axes[i]\n",
    "    words, counts = zip(*top_10)\n",
    "    ax.bar(words, counts, color=colors)\n",
    "    ax.set_title(f'Sentiment: {sentiment_class}') \n",
    "    ax.set_xticklabels(words, rotation=45, ha='right')\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a99040e-5a3c-4726-b8b8-3e53ec0c26d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94f7b2c3-cf70-4c1a-89a9-9b0abe31bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [dense, una, vuelta, por, para, ver, la, gran,...\n",
       "1       [hey, folk, free, lunch, from, la, condesa, at...\n",
       "2       [the, countdown, to, ha, begun, will, be, ther...\n",
       "3       [rt, why, google, apple, ea, game, zynga, face...\n",
       "4       [the, line, wa, too, long, the, other, day, bu...\n",
       "                              ...                        \n",
       "4783    [rt, ill, be, at, the, apple, store, tonight, ...\n",
       "4784    [msft, panel, on, touch, interface, show, a, b...\n",
       "4785    [questioner, at, just, said, quot, thanks, and...\n",
       "4786    [rt, rt, yes, updated, iphone, app, ha, song, ...\n",
       "4787    [the, pressure, ahem, excuse, to, buy, mount, ...\n",
       "Length: 4788, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_und = RandomUnderSampler(random_state=24)\n",
    "\n",
    "X_train_str = X_train.apply(' '.join) \n",
    "X_train_resampled, y_train_resampled = rand_und.fit_resample(X_train_str.values.reshape(-1, 1), y_train)\n",
    "X_train_resampled_tokens = pd.Series([sample[0].split(' ') for sample in X_train_resampled])\n",
    "X_train_resampled_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c0a51df-e4e7-4c62-a777-24756e685d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out the word distrobutions in X_train for each target class\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "color_palette = sns.color_palette('cividis', n_colors=38)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(12, 12)) \n",
    "\n",
    "plotted_words_and_colors = {}\n",
    "\n",
    "sentiment_classes = y_train.unique() \n",
    "for i, sentiment_class in enumerate(sentiment_classes):\n",
    "    sentiment_data = X_train_resampled_tokens[y_train_resampled == sentiment_class]\n",
    "    all_words_in_sentiment = [word for tokens in sentiment_data for word in tokens]\n",
    "    top_10 = Counter(all_words_in_sentiment).most_common(20)\n",
    "    \n",
    "    colors = []\n",
    "    \n",
    "    for word, _ in top_10:\n",
    "        if word not in plotted_words_and_colors:\n",
    "            new_color = color_palette.pop(0)\n",
    "            plotted_words_and_colors[word] = new_color\n",
    "        colors.append(plotted_words_and_colors[word])\n",
    "    \n",
    "    ax = axes[i]\n",
    "    words, counts = zip(*top_10)\n",
    "    ax.bar(words, counts, color=colors)\n",
    "    ax.set_title(f'Sentiment: {sentiment_class}') \n",
    "    ax.set_xticklabels(words, rotation=45, ha='right')\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616a4754-621e-46ad-96c4-94ba031f628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join token lists into strings\n",
    "X_train_str = X_train.apply(' '.join)\n",
    "X_val_str = X_val.apply(' '.join)\n",
    "X_test_str = X_test.apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81ccfb28-1003-4514-8226-e2e350b62c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7130"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "425ba006-1bf2-4260-a5f6-880003fd35a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=2000, min_df=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=2000, min_df=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=2000, min_df=0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector= TfidfVectorizer(max_features= 2000, ngram_range= (1,1), min_df= 0.0, max_df= 1.0)\n",
    "vector.fit(X_train_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4736cf98-2f09-4854-bb11-468db8d300fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb53a194-6344-499d-a849-96b8af4e2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector= TfidfVectorizer(max_features= 2000, ngram_range= (1,1), min_df= .001, max_df= 1.0)\n",
    "#vector.fit(X_train_str.tolist())\n",
    "#list(vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b50b227a-ec1a-402e-a108-49ee0e5a0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8febbe-83a6-4032-b23b-8f664af3d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list= stopwords.words('english')\n",
    "stopwords_list = [word for word in stopwords_list if word not in ['not', 'can']]\n",
    "#possibly append words to the list of stop words\n",
    "additional_stopwords= ['google', 'iphone', 'ipad', 'link', 'apple', 'rt', 'store', 'quot', 'austin', 'via', 'sxsw']\n",
    "stopwords_list2= stopwords_list + additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f37fdc0d-ed68-47f9-9f10-e3e2211fed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7304\n",
      "Validation Set Accuracy: 0.7565\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True, False]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "477d5c43-906c-440a-ba14-dccc5b0385c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nBest Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7304\\nValidation Set Accuracy: 0.7565\\n\\n\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7304\n",
    "Validation Set Accuracy: 0.7565\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a56a25d-3980-4673-8ee2-8573d24b238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7278\n",
      "Validation Set Accuracy: 0.7475\n"
     ]
    }
   ],
   "source": [
    "#v1.1\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a009f7-c5cd-4021-9b3c-437f5e181425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_tokenized</th>\n",
       "      <th>tweet_len</th>\n",
       "      <th>tweet_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>great ipad app from http://tinyurl.com/4nqv92l</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, ipad, app, from]</td>\n",
       "      <td>4</td>\n",
       "      <td>[great, ipad, app, from]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>÷¼ what? ÷_ {link} ã_</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, link]</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>i worship {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, worship, link]</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, worship, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>stay tune showcase {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[stay, tune, showcase, link]</td>\n",
       "      <td>4</td>\n",
       "      <td>[stay, tune, showcase, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>follow lead {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[follow, lead, link]</td>\n",
       "      <td>3</td>\n",
       "      <td>[follow, lead, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>well put. totally agree!</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[well, put, totally, agree]</td>\n",
       "      <td>4</td>\n",
       "      <td>[well, put, totally, agree]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>black or white ipad?</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[black, or, white, ipad]</td>\n",
       "      <td>4</td>\n",
       "      <td>[black, or, white, ipad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>google arwords, arsense anyone?</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[google, arwords, arsense, anyone]</td>\n",
       "      <td>4</td>\n",
       "      <td>[google, arwords, arsense, anyone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9031</th>\n",
       "      <td>... or maybe not: {link}</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>0</td>\n",
       "      <td>[or, maybe, not, link]</td>\n",
       "      <td>4</td>\n",
       "      <td>[or, maybe, not, link]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>ipad everywhere. {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>[ipad, everywhere, link]</td>\n",
       "      <td>3</td>\n",
       "      <td>[ipad, everywhere, link]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "14    great ipad app from http://tinyurl.com/4nqv92l   \n",
       "52                          ÷¼ what? ÷_ {link} ã_   \n",
       "77                                  i worship {link}   \n",
       "85                         stay tune showcase {link}   \n",
       "133                               follow lead {link}   \n",
       "...                                              ...   \n",
       "8885                        well put. totally agree!   \n",
       "8904                            black or white ipad?   \n",
       "8923                 google arwords, arsense anyone?   \n",
       "9031                        ... or maybe not: {link}   \n",
       "9088                         ipad everywhere. {link}   \n",
       "\n",
       "                                 emotion  sentiment  \\\n",
       "14                      Positive emotion          1   \n",
       "52    No emotion toward brand or product          0   \n",
       "77    No emotion toward brand or product          0   \n",
       "85    No emotion toward brand or product          0   \n",
       "133   No emotion toward brand or product          0   \n",
       "...                                  ...        ...   \n",
       "8885  No emotion toward brand or product          0   \n",
       "8904  No emotion toward brand or product          0   \n",
       "8923  No emotion toward brand or product          0   \n",
       "9031  No emotion toward brand or product          0   \n",
       "9088                    Positive emotion          1   \n",
       "\n",
       "                         tweet_tokenized  tweet_len  \\\n",
       "14              [great, ipad, app, from]          4   \n",
       "52                          [what, link]          2   \n",
       "77                    [i, worship, link]          3   \n",
       "85          [stay, tune, showcase, link]          4   \n",
       "133                 [follow, lead, link]          3   \n",
       "...                                  ...        ...   \n",
       "8885         [well, put, totally, agree]          4   \n",
       "8904            [black, or, white, ipad]          4   \n",
       "8923  [google, arwords, arsense, anyone]          4   \n",
       "9031              [or, maybe, not, link]          4   \n",
       "9088            [ipad, everywhere, link]          3   \n",
       "\n",
       "                               tweet_lem  \n",
       "14              [great, ipad, app, from]  \n",
       "52                          [what, link]  \n",
       "77                    [i, worship, link]  \n",
       "85          [stay, tune, showcase, link]  \n",
       "133                 [follow, lead, link]  \n",
       "...                                  ...  \n",
       "8885         [well, put, totally, agree]  \n",
       "8904            [black, or, white, ipad]  \n",
       "8923  [google, arwords, arsense, anyone]  \n",
       "9031              [or, maybe, not, link]  \n",
       "9088            [ipad, everywhere, link]  \n",
       "\n",
       "[86 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_raw_df[rel_raw_df['tweet_len']<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b08f4ef6-7b3e-4e4a-ba1f-5c2ab9f8294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2500, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7303\n",
      "Validation Set Accuracy: 0.7305\n"
     ]
    }
   ],
   "source": [
    "#run this on the dataset where all X_train tweets are >=5 in length \n",
    "rel_raw_df_long= rel_raw_df[rel_raw_df['tweet_len']>=5]\n",
    "\n",
    "rel_raw_df_long['tweet_lem'] = rel_raw_df_long['tweet_tokenized'].apply(lem_tokens)\n",
    "\n",
    "X_long= rel_raw_df_long['tweet_lem']\n",
    "y_long= rel_raw_df_long['sentiment']\n",
    "\n",
    "\n",
    "\n",
    "#Train split (remain is the remaining data)\n",
    "X_train_long, X_remain_long, y_train_long, y_remain_long= train_test_split(X_long, y_long, \n",
    "                                                   test_size= 0.2,  \n",
    "                                                   random_state= 24)\n",
    "\n",
    "#Val test split \n",
    "X_val_long, X_test_long, y_val_long, y_test_long= train_test_split(X_remain_long, y_remain_long,\n",
    "                                               test_size= 0.5, \n",
    "                                               random_state= 24)\n",
    "\n",
    "\n",
    "X_train_str_long = X_train_long.apply(' '.join)\n",
    "X_val_str_long = X_val_long.apply(' '.join)\n",
    "X_test_str_long = X_test_long.apply(' '.join)\n",
    "\n",
    "pipeline_long = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True, False]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search_long = GridSearchCV(\n",
    "    pipeline_long,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search_long.fit(X_train_str_long, y_train_long)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search_long.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search_long.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_long = best_model.predict(X_val_str_long)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "val_accuracy = accuracy_score(y_val_long, y_val_pred_long)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search_long.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd2938-79fb-48d1-9224-ebede58d3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2500, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7303\n",
    "Validation Set Accuracy: 0.7305\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4e367-d7f3-4dd4-9188-ab4789aa13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this on the dataset where all X_train tweets are >=5 in length \n",
    "rel_raw_df_long= rel_raw_df[rel_raw_df['tweet_len']>=5]\n",
    "\n",
    "rel_raw_df_long['tweet_lem'] = rel_raw_df_long['tweet_tokenized'].apply(lem_tokens)\n",
    "\n",
    "X_long= rel_raw_df_long['tweet_lem']\n",
    "y_long= rel_raw_df_long['sentiment']\n",
    "\n",
    "\n",
    "\n",
    "#Train split (remain is the remaining data)\n",
    "X_train_long, X_remain_long, y_train_long, y_remain_long= train_test_split(X_long, y_long, \n",
    "                                                   test_size= 0.2,  \n",
    "                                                   random_state= 24)\n",
    "\n",
    "#Val test split \n",
    "X_val_long, X_test_long, y_val_long, y_test_long= train_test_split(X_remain_long, y_remain_long,\n",
    "                                               test_size= 0.5, \n",
    "                                               random_state= 24)\n",
    "\n",
    "\n",
    "X_train_str_long = X_train_long.apply(' '.join)\n",
    "X_val_str_long = X_val_long.apply(' '.join)\n",
    "X_test_str_long = X_test_long.apply(' '.join)\n",
    "\n",
    "pipeline_long = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True, False]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search_long = GridSearchCV(\n",
    "    pipeline_long,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search_long.fit(X_train_str_long, y_train_long)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search_long.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search_long.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_long = best_model.predict(X_val_str_long)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "val_accuracy = accuracy_score(y_val_long, y_val_pred_long)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search_long.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da98504-6142-4a1b-bb06-0fb73d4bb1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360065b-cc32-49df-b8ef-b5fd9a1a95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1: train test split\n",
    "step: calc length on x train \n",
    "step: filter x train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5797bc72-ec86-4221-8ae2-0613e6f30772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_lem</th>\n",
       "      <th>tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, have, a, iphone, after, hr, tweeting, at, ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[know, about, awesome, ipad, iphone, app, that...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cant, wait, for, also, they, should, sale, th...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, hope, this, year, festival, isnt, a, crash...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[great, stuff, on, fri, marissa, mayer, google...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_lem  tweet_len\n",
       "0  [i, have, a, iphone, after, hr, tweeting, at, ...         18\n",
       "1  [know, about, awesome, ipad, iphone, app, that...         19\n",
       "2  [cant, wait, for, also, they, should, sale, th...         10\n",
       "3  [i, hope, this, year, festival, isnt, a, crash...         13\n",
       "4  [great, stuff, on, fri, marissa, mayer, google...         16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= rel_raw_df[['tweet_lem', 'tweet_len']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff0f4a08-8b6b-48de-91a9-24ca08e80f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]}\n",
      "Best Train Cross-Validation Score: 0.7275\n",
      "Validation Set Accuracy: 0.7508\n"
     ]
    }
   ],
   "source": [
    "#run this on the dataset where all X_train tweets are >=5 in length but best and val are unstripped\n",
    "rel_raw_df_long= rel_raw_df[rel_raw_df['tweet_len']>=5]\n",
    "\n",
    "rel_raw_df_long['tweet_lem'] = rel_raw_df_long['tweet_tokenized'].apply(lem_tokens)\n",
    "\n",
    "X_long= rel_raw_df_long['tweet_lem']\n",
    "y_long= rel_raw_df_long['sentiment']\n",
    "\n",
    "X= rel_raw_df[['tweet_lem', 'tweet_len']]\n",
    "y= rel_raw_df[['sentiment', 'tweet_len']]\n",
    "\n",
    "#Train split (remain is the remaining data)\n",
    "X_train, X_remain, y_train, y_remain= train_test_split(X, y, \n",
    "                                                   test_size= 0.2,  \n",
    "                                                   random_state= 24)\n",
    "\n",
    "#Val test split \n",
    "X_val, X_test, y_val, y_test= train_test_split(X_remain, y_remain,\n",
    "                                               test_size= 0.5, \n",
    "                                               random_state= 24)\n",
    "\n",
    "X_train= X_train[X_train['tweet_len']>=5]\n",
    "y_train= y_train[y_train['tweet_len']>=5]\n",
    "\n",
    "X_train= X_train['tweet_lem']\n",
    "y_train= y_train['sentiment']\n",
    "X_val= X_val['tweet_lem']\n",
    "X_test= X_test['tweet_lem']\n",
    "y_val= y_val['sentiment']\n",
    "y_test= y_test['sentiment']\n",
    "\n",
    "X_train_str = X_train.apply(' '.join)\n",
    "X_val_str = X_val.apply(' '.join)\n",
    "X_test_str = X_test.apply(' '.join)\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid2 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search= GridSearchCV(\n",
    "    pipeline2,\n",
    "    param_grid2,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52695fe0-1989-4f67-b27a-f08efcf63a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]}\n",
    "Best Train Cross-Validation Score: 0.7275\n",
    "Validation Set Accuracy: 0.7508\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c67ee7-0fb5-44a8-8713-bb8be1546dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this on the dataset where all X_train tweets are >=5 in length but best and val are unstripped v2 diff params\n",
    "rel_raw_df_long= rel_raw_df[rel_raw_df['tweet_len']>=5]\n",
    "\n",
    "rel_raw_df_long['tweet_lem'] = rel_raw_df_long['tweet_tokenized'].apply(lem_tokens)\n",
    "\n",
    "X_long= rel_raw_df_long['tweet_lem']\n",
    "y_long= rel_raw_df_long['sentiment']\n",
    "\n",
    "X= rel_raw_df[['tweet_lem', 'tweet_len']]\n",
    "y= rel_raw_df[['sentiment', 'tweet_len']]\n",
    "\n",
    "#Train split (remain is the remaining data)\n",
    "X_train, X_remain, y_train, y_remain= train_test_split(X, y, \n",
    "                                                   test_size= 0.2,  \n",
    "                                                   random_state= 24)\n",
    "\n",
    "#Val test split \n",
    "X_val, X_test, y_val, y_test= train_test_split(X_remain, y_remain,\n",
    "                                               test_size= 0.5, \n",
    "                                               random_state= 24)\n",
    "\n",
    "X_train= X_train[X_train['tweet_len']>=5]\n",
    "y_train= y_train[y_train['tweet_len']>=5]\n",
    "\n",
    "X_train= X_train['tweet_lem']\n",
    "y_train= y_train['sentiment']\n",
    "X_val= X_val['tweet_lem']\n",
    "X_test= X_test['tweet_lem']\n",
    "y_val= y_val['sentiment']\n",
    "y_test= y_test['sentiment']\n",
    "\n",
    "X_train_str = X_train.apply(' '.join)\n",
    "X_val_str = X_val.apply(' '.join)\n",
    "X_test_str = X_test.apply(' '.join)\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24))])\n",
    "#make a parameter grid\n",
    "param_grid2 = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1,2), (1,3)],\n",
    "    'tfidf__min_df': [0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.65, 0.85, 1.0],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None],\n",
    "    'clf__C': [0.01, 1 10],                  # 4\n",
    "    'clf__fit_intercept': [True, False],            # 2\n",
    "    'clf__class_weight': [None, 'balanced', {0: 1, 1: 1.5}],  # 3\n",
    "    'clf__solver': ['lbfgs', 'liblinear', 'saga'],  # 3\n",
    "    'clf__tol': [1e-4, 1e-2]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search= GridSearchCV(\n",
    "    pipeline2,\n",
    "    param_grid2,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1820898-5067-4b57-b981-2b779b22fd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8af0b66b-4a4a-4882-aac3-c530bf456998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 1.0, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2)}\n",
      "Best Train Cross-Validation Score: 0.6748\n",
      "Validation Set Accuracy: 0.6891\n"
     ]
    }
   ],
   "source": [
    "#run this on the random undersampled dataset\n",
    "#this seems to hurt things\n",
    "\n",
    "# Join token lists into strings\n",
    "X_train_str_ru = X_train_resampled_tokens.apply(' '.join)\n",
    "X_val_str = X_val.apply(' '.join)\n",
    "X_test_str = X_test.apply(' '.join)\n",
    "\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "    'tfidf__max_df': [1.0]}\n",
    "\n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str_ru, y_train_resampled)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a27aa0-6510-40b1-a8c3-732517a71214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 1.0, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2)}\n",
    "Best Train Cross-Validation Score: 0.6748\n",
    "Validation Set Accuracy: 0.6891\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdd8b6e5-61fe-44b0-a7c8-f0312a6733ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ee8340a-ffa9-4a36-9c81-d336ae229b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 1.0, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3)}\n",
      "Best Train Cross-Validation Score: 0.7234\n",
      "Validation Set Accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "#run this on the adjusted stopword dataset\n",
    "\n",
    "stopwords_list= stopwords.words('english')\n",
    "stopwords_list = [word for word in stopwords_list if word not in ['not', 'can']]\n",
    "#possibly append words to the list of stop words\n",
    "additional_stopwords= ['google', 'iphone', 'ipad', 'link', 'apple', 'rt', 'store', 'quot', 'austin', 'via', 'sxsw']\n",
    "stopwords_list2= stopwords_list + additional_stopwords\n",
    "\n",
    "def remove_stopwords2(token_list):\n",
    "    list_stripped= [x for x in token_list if x not in stopwords_list2]\n",
    "    return list_stripped\n",
    "\n",
    "rel_raw_df['tweet_tokenized_ns2']= rel_raw_df['tweet_tokenized'].apply(remove_stopwords2)\n",
    "\n",
    "rel_raw_df['tweet_lem2'] = rel_raw_df['tweet_tokenized_ns2'].apply(lem_tokens)\n",
    "\n",
    "X= rel_raw_df['tweet_lem2']\n",
    "y= rel_raw_df['sentiment']\n",
    "\n",
    "#Train split (remain is the remaining data)\n",
    "X_train2, X_remain2, y_train, y_remain= train_test_split(X, y, \n",
    "                                                   test_size= 0.2,  \n",
    "                                                   random_state= 24)\n",
    "\n",
    "#Val test split \n",
    "X_val2, X_test2, y_val, y_test= train_test_split(X_remain2, y_remain,\n",
    "                                               test_size= 0.5, \n",
    "                                               random_state= 24)\n",
    "\n",
    "# Join token lists into strings\n",
    "X_train_str2= X_train2.apply(' '.join)\n",
    "X_val_str2= X_val2.apply(' '.join)\n",
    "X_test_str2= X_test2.apply(' '.join)\n",
    "\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (2,2), (1,3), (3,3), (1,5), (5,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "    'tfidf__max_df': [1.0]}\n",
    "\n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str2, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str2)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506d23d-62d4-458a-bf7c-bd0e3555d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 1.0, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3)}\n",
    "Best Train Cross-Validation Score: 0.7234\n",
    "Validation Set Accuracy: 0.7430\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3742a6-1655-4b17-b51e-d1c015e3846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list_1= X_train_str[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd533d8e-2157-4050-815f-116da69372ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.8, 'tfidf__max_features': 3000, 'tfidf__min_df': 0.2, 'tfidf__ngram_range': (1, 2)}\n",
      "Best Train Cross-Validation Score: 0.6642\n",
      "Validation Set Accuracy: 0.6846\n"
     ]
    }
   ],
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3000],\n",
    "    'tfidf__ngram_range': [(1, 2)],\n",
    "    'tfidf__min_df': [0.2],\n",
    "    'tfidf__max_df': [0.8]}\n",
    "\n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ee8a4-4f4a-4b7b-80b5-d7d4c17726e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.8, 'tfidf__max_features': 3000, 'tfidf__min_df': 0.2, 'tfidf__ngram_range': (1, 2)}\n",
    "Best Train Cross-Validation Score: 0.6642\n",
    "Validation Set Accuracy: 0.6846\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aaa88da-f711-4598-af65-d429f40069db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list_2= X_train_str[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6bd4d1c-568a-4cb4-b89b-050bc002cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2915              opening popup shop downtown austin link\n",
       "6476    rt remember chime tweet experience central tim...\n",
       "6347     rt new app store inclds uberguide sponsored link\n",
       "8164                  sxsw first lecture phone turn stove\n",
       "8877    crowley growing foursquare competitor facebook...\n",
       "                              ...                        \n",
       "8805                          loving new iphone w channel\n",
       "959                        omgjk kiss ipad slap xoom link\n",
       "8864    crowd austin swarm ipad launch link via sadly ...\n",
       "3012    ahh wonderful news rt ipad available online or...\n",
       "332     long line apple pop store ipad great marketing...\n",
       "Name: tweet_lem, Length: 100, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list_2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5717931b-d4b4-4afa-aadd-4f9313c1aa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2915              opening popup shop downtown austin link\n",
       "6476    rt remember chime tweet experience central tim...\n",
       "6347     rt new app store inclds uberguide sponsored link\n",
       "8164                  sxsw first lecture phone turn stove\n",
       "8877    crowley growing foursquare competitor facebook...\n",
       "                              ...                        \n",
       "8805                          loving new iphone w channel\n",
       "959                        omgjk kiss ipad slap xoom link\n",
       "8864    crowd austin swarm ipad launch link via sadly ...\n",
       "3012    ahh wonderful news rt ipad available online or...\n",
       "332     long line apple pop store ipad great marketing...\n",
       "Name: tweet_lem, Length: 100, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list_1[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae7a7c-dbf0-4428-b6aa-198e2a342c6f",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8552c09-2d08-4fce-a004-52649fb2fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c984ea1-ac17-4c65-a481-b7621d405f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nBest Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7304\\nValidation Set Accuracy: 0.7565\\n\\n\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7304\n",
    "Validation Set Accuracy: 0.7565\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "553f9b2e-96e4-4b18-81a6-857263e7bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7278\n",
      "Validation Set Accuracy: 0.7475\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 50, 100],\n",
    "    'tfidf__max_df': [0.95, 1],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5116540-0bdb-4060-ad78-189ef35f37d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBest Hyperparameters: {\\'tfidf__max_df\\': 0.75, \\'tfidf__max_features\\': 4000, \\'tfidf__min_df\\': 0.0, \\'tfidf__ngram_range\\': (1, 3), \\'tfidf__stop_words\\': [\\'a\\', \\'about\\', \\'above\\', \\'after\\', \\'again\\', \\'against\\', \\'ain\\', \\'all\\', \\'am\\', \\'an\\', \\'and\\', \\'any\\', \\'are\\', \\'aren\\', \"aren\\'t\", \\'as\\', \\'at\\', \\'be\\', \\'because\\', \\'been\\', \\'before\\', \\'being\\', \\'below\\', \\'between\\', \\'both\\', \\'but\\', \\'by\\', \\'couldn\\', \"couldn\\'t\", \\'d\\', \\'did\\', \\'didn\\', \"didn\\'t\", \\'do\\', \\'does\\', \\'doesn\\', \"doesn\\'t\", \\'doing\\', \\'don\\', \"don\\'t\", \\'down\\', \\'during\\', \\'each\\', \\'few\\', \\'for\\', \\'from\\', \\'further\\', \\'had\\', \\'hadn\\', \"hadn\\'t\", \\'has\\', \\'hasn\\', \"hasn\\'t\", \\'have\\', \\'haven\\', \"haven\\'t\", \\'having\\', \\'he\\', \"he\\'d\", \"he\\'ll\", \\'her\\', \\'here\\', \\'hers\\', \\'herself\\', \"he\\'s\", \\'him\\', \\'himself\\', \\'his\\', \\'how\\', \\'i\\', \"i\\'d\", \\'if\\', \"i\\'ll\", \"i\\'m\", \\'in\\', \\'into\\', \\'is\\', \\'isn\\', \"isn\\'t\", \\'it\\', \"it\\'d\", \"it\\'ll\", \"it\\'s\", \\'its\\', \\'itself\\', \"i\\'ve\", \\'just\\', \\'ll\\', \\'m\\', \\'ma\\', \\'me\\', \\'mightn\\', \"mightn\\'t\", \\'more\\', \\'most\\', \\'mustn\\', \"mustn\\'t\", \\'my\\', \\'myself\\', \\'needn\\', \"needn\\'t\", \\'no\\', \\'nor\\', \\'now\\', \\'o\\', \\'of\\', \\'off\\', \\'on\\', \\'once\\', \\'only\\', \\'or\\', \\'other\\', \\'our\\', \\'ours\\', \\'ourselves\\', \\'out\\', \\'over\\', \\'own\\', \\'re\\', \\'s\\', \\'same\\', \\'shan\\', \"shan\\'t\", \\'she\\', \"she\\'d\", \"she\\'ll\", \"she\\'s\", \\'should\\', \\'shouldn\\', \"shouldn\\'t\", \"should\\'ve\", \\'so\\', \\'some\\', \\'such\\', \\'t\\', \\'than\\', \\'that\\', \"that\\'ll\", \\'the\\', \\'their\\', \\'theirs\\', \\'them\\', \\'themselves\\', \\'then\\', \\'there\\', \\'these\\', \\'they\\', \"they\\'d\", \"they\\'ll\", \"they\\'re\", \"they\\'ve\", \\'this\\', \\'those\\', \\'through\\', \\'to\\', \\'too\\', \\'under\\', \\'until\\', \\'up\\', \\'ve\\', \\'very\\', \\'was\\', \\'wasn\\', \"wasn\\'t\", \\'we\\', \"we\\'d\", \"we\\'ll\", \"we\\'re\", \\'were\\', \\'weren\\', \"weren\\'t\", \"we\\'ve\", \\'what\\', \\'when\\', \\'where\\', \\'which\\', \\'while\\', \\'who\\', \\'whom\\', \\'why\\', \\'will\\', \\'with\\', \\'won\\', \"won\\'t\", \\'wouldn\\', \"wouldn\\'t\", \\'y\\', \\'you\\', \"you\\'d\", \"you\\'ll\", \\'your\\', \"you\\'re\", \\'yours\\', \\'yourself\\', \\'yourselves\\', \"you\\'ve\"], \\'tfidf__sublinear_tf\\': True, \\'tfidf__use_idf\\': True}\\nBest Train Cross-Validation Score: 0.7278\\nValidation Set Accuracy: 0.7475\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.75, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7278\n",
    "Validation Set Accuracy: 0.7475\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "054cf4d8-a9f7-43f3-a098-d02415f840c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7275\n",
      "Validation Set Accuracy: 0.7531\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1,2), (2,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 2],\n",
    "    'tfidf__max_df': [0.95, 1],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0ffcf94-0412-413b-a29e-48991c1e3d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7275\\nValidation Set Accuracy: 0.7531\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7275\n",
    "Validation Set Accuracy: 0.7531\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47fae27d-07c6-4154-a8ae-1bd236e108f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7278\n",
      "Validation Set Accuracy: 0.7475\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24, \n",
    "                               C=1,\n",
    "                               class_weight=None,\n",
    "                               fit_intercept=True,\n",
    "                               solver='saga',\n",
    "                               tol=0.0001))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1,2), (2,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 2],\n",
    "    'tfidf__max_df': [0.95, 1],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3cc7325-1051-4eb5-928a-8a710bf8afd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nBest Hyperparameters: {\\'tfidf__max_df\\': 0.95, \\'tfidf__max_features\\': 4000, \\'tfidf__min_df\\': 0.0, \\'tfidf__ngram_range\\': (1, 3), \\'tfidf__stop_words\\': [\\'a\\', \\'about\\', \\'above\\', \\'after\\', \\'again\\', \\'against\\', \\'ain\\', \\'all\\', \\'am\\', \\'an\\', \\'and\\', \\'any\\', \\'are\\', \\'aren\\', \"aren\\'t\", \\'as\\', \\'at\\', \\'be\\', \\'because\\', \\'been\\', \\'before\\', \\'being\\', \\'below\\', \\'between\\', \\'both\\', \\'but\\', \\'by\\', \\'couldn\\', \"couldn\\'t\", \\'d\\', \\'did\\', \\'didn\\', \"didn\\'t\", \\'do\\', \\'does\\', \\'doesn\\', \"doesn\\'t\", \\'doing\\', \\'don\\', \"don\\'t\", \\'down\\', \\'during\\', \\'each\\', \\'few\\', \\'for\\', \\'from\\', \\'further\\', \\'had\\', \\'hadn\\', \"hadn\\'t\", \\'has\\', \\'hasn\\', \"hasn\\'t\", \\'have\\', \\'haven\\', \"haven\\'t\", \\'having\\', \\'he\\', \"he\\'d\", \"he\\'ll\", \\'her\\', \\'here\\', \\'hers\\', \\'herself\\', \"he\\'s\", \\'him\\', \\'himself\\', \\'his\\', \\'how\\', \\'i\\', \"i\\'d\", \\'if\\', \"i\\'ll\", \"i\\'m\", \\'in\\', \\'into\\', \\'is\\', \\'isn\\', \"isn\\'t\", \\'it\\', \"it\\'d\", \"it\\'ll\", \"it\\'s\", \\'its\\', \\'itself\\', \"i\\'ve\", \\'just\\', \\'ll\\', \\'m\\', \\'ma\\', \\'me\\', \\'mightn\\', \"mightn\\'t\", \\'more\\', \\'most\\', \\'mustn\\', \"mustn\\'t\", \\'my\\', \\'myself\\', \\'needn\\', \"needn\\'t\", \\'no\\', \\'nor\\', \\'now\\', \\'o\\', \\'of\\', \\'off\\', \\'on\\', \\'once\\', \\'only\\', \\'or\\', \\'other\\', \\'our\\', \\'ours\\', \\'ourselves\\', \\'out\\', \\'over\\', \\'own\\', \\'re\\', \\'s\\', \\'same\\', \\'shan\\', \"shan\\'t\", \\'she\\', \"she\\'d\", \"she\\'ll\", \"she\\'s\", \\'should\\', \\'shouldn\\', \"shouldn\\'t\", \"should\\'ve\", \\'so\\', \\'some\\', \\'such\\', \\'t\\', \\'than\\', \\'that\\', \"that\\'ll\", \\'the\\', \\'their\\', \\'theirs\\', \\'them\\', \\'themselves\\', \\'then\\', \\'there\\', \\'these\\', \\'they\\', \"they\\'d\", \"they\\'ll\", \"they\\'re\", \"they\\'ve\", \\'this\\', \\'those\\', \\'through\\', \\'to\\', \\'too\\', \\'under\\', \\'until\\', \\'up\\', \\'ve\\', \\'very\\', \\'was\\', \\'wasn\\', \"wasn\\'t\", \\'we\\', \"we\\'d\", \"we\\'ll\", \"we\\'re\", \\'were\\', \\'weren\\', \"weren\\'t\", \"we\\'ve\", \\'what\\', \\'when\\', \\'where\\', \\'which\\', \\'while\\', \\'who\\', \\'whom\\', \\'why\\', \\'will\\', \\'with\\', \\'won\\', \"won\\'t\", \\'wouldn\\', \"wouldn\\'t\", \\'y\\', \\'you\\', \"you\\'d\", \"you\\'ll\", \\'your\\', \"you\\'re\", \\'yours\\', \\'yourself\\', \\'yourselves\\', \"you\\'ve\"], \\'tfidf__sublinear_tf\\': True, \\'tfidf__use_idf\\': True}\\nBest Train Cross-Validation Score: 0.7278\\nValidation Set Accuracy: 0.7475\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 3), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7278\n",
    "Validation Set Accuracy: 0.7475\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ddf579d-27f1-4aa7-91f4-0dee98bd8991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__fit_intercept': True, 'clf__solver': 'liblinear', 'clf__tol': 0.0001, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7275\n",
      "Validation Set Accuracy: 0.7531\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__C': [0.01, 0.1, 1, 10],                  # 4\n",
    "    'clf__fit_intercept': [True, False],            # 2\n",
    "    'clf__class_weight': [None, 'balanced', {0: 1, 1: 1.5}],  # 3\n",
    "    'clf__solver': ['lbfgs', 'liblinear', 'saga'],  # 3\n",
    "    'clf__tol': [1e-4, 1e-3, 1e-2]}                 # 3}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf44d04-4ce1-49f4-af98-6b640dd198a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\", 'google', 'iphone', 'ipad', 'link', 'apple', 'rt', 'store', 'quot', 'austin', 'via', 'sxsw'], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7230\n",
    "Validation Set Accuracy: 0.7396\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936571ca-7e2a-4c7a-949c-14820ae49bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__fit_intercept': True, 'clf__solver': 'liblinear', 'clf__tol': 0.0001, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7275\n",
    "Validation Set Accuracy: 0.7531\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "145162d8-cba6-415e-a2c3-02fa5737c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__fit_intercept': True, 'clf__solver': 'liblinear', 'clf__tol': 1e-06, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7277\n",
      "Validation Set Accuracy: 0.7531\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3000, 3500],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__C': [0, 1, 2],                  # 4\n",
    "    'clf__fit_intercept': [True, False],            # 2\n",
    "    'clf__class_weight': [None],  # 3\n",
    "    'clf__solver': ['liblinear'],  # 3\n",
    "    'clf__tol': [1e-6, 1e-5, 1e-4, 1e-3]}                 # 3}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6a1f656-4747-4407-bfd5-609724f8700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__fit_intercept': True, 'clf__solver': 'liblinear', 'clf__tol': 1e-06, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7277\n",
      "Validation Set Accuracy: 0.7531\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(random_state=24))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__C': [1],                  # 4\n",
    "    'clf__fit_intercept': [True, False],            # 2\n",
    "    'clf__class_weight': [None],  # 3\n",
    "    'clf__solver': ['liblinear'],  # 3\n",
    "    'clf__tol': [1e-6]}                 # 3}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaadbaf-5543-4c07-a3c9-6610eab10295",
   "metadata": {},
   "source": [
    "### best log reg score train 0.7277 val 0.7531"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c33ebc-e4f4-417e-b048-1edaf3b5ea51",
   "metadata": {},
   "source": [
    "# xg boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7518064a-1762-4d7e-a761-4022976e3381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 2, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.6995\n",
      "Validation Set Accuracy: 0.7273\n",
      "\n",
      "Comparison:\n",
      "Logistic Regression (Base) Validation Accuracy: 0.7576\n",
      "XGBoost Validation Accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "# Base param grid for TF-IDF\n",
    "base_param_grid = {\n",
    "    'tfidf__max_features': [3500, 4000],\n",
    "    'tfidf__ngram_range': [(1,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 0.01],\n",
    "    'tfidf__max_df': [0.85, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "# XGBoost Pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', XGBClassifier(random_state=24, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    **base_param_grid,\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [3, 5],\n",
    "    'clf__learning_rate': [0.1, 0.3],  # Default is 0.3\n",
    "    'clf__scale_pos_weight': [2]}\n",
    "\n",
    "# Run grid search\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search_xgb.fit(X_train_str, y_train)\n",
    "\n",
    "# Results\n",
    "best_train_cv_score_xgb = grid_search_xgb.best_score_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "y_val_pred_xgb = best_model_xgb.predict(X_val_str)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_xgb}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score_xgb:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0c342af-8ccf-481b-ae0f-b6535910b3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFitting 5 folds for each of 256 candidates, totalling 1280 fits\\n\\nXGBoost Results:\\nBest Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 2, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.6995\\nValidation Set Accuracy: 0.7273\\n\\nComparison:\\nLogistic Regression (Base) Validation Accuracy: 0.7576\\nXGBoost Validation Accuracy: 0.7273\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
    "\n",
    "XGBoost Results:\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 2, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.6995\n",
    "Validation Set Accuracy: 0.7273\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ff55f2-709c-4f47-a0e4-1d2b02d86939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7239\n",
      "Validation Set Accuracy: 0.7497\n"
     ]
    }
   ],
   "source": [
    "# Base param grid for TF-IDF\n",
    "base_param_grid = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 0.0001],\n",
    "    'tfidf__max_df': [0.85],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "# XGBoost Pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', XGBClassifier(random_state=24, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    **base_param_grid,\n",
    "    'clf__n_estimators': [200, 300],\n",
    "    'clf__max_depth': [4, 5, 6],\n",
    "    'clf__learning_rate': [0.3, 0.4],  # Default is 0.3\n",
    "    'clf__scale_pos_weight': [1, 2, 3]}\n",
    "\n",
    "# Run grid search\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search_xgb.fit(X_train_str, y_train)\n",
    "\n",
    "# Results\n",
    "best_train_cv_score_xgb = grid_search_xgb.best_score_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "y_val_pred_xgb = best_model_xgb.predict(X_val_str)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_xgb}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score_xgb:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02191a15-d1b3-45d0-bdfa-53272cb55517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an improvement from the previous xgb\n",
    "\n",
    "\"\"\"\n",
    "XGBoost Results:\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7239\n",
    "Validation Set Accuracy: 0.7497\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d33eef79-5900-47de-96bc-5db26ac5dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7239\n",
      "Validation Set Accuracy: 0.7497\n"
     ]
    }
   ],
   "source": [
    "# Base param grid for TF-IDF\n",
    "base_param_grid = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 0.0001],\n",
    "    'tfidf__max_df': [0.85],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "# XGBoost Pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', XGBClassifier(random_state=24, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    **base_param_grid,\n",
    "    'clf__n_estimators': [175, 200, 225],\n",
    "    'clf__max_depth': [5],\n",
    "    'clf__learning_rate': [0.2, 0.3],  # Default is 0.3\n",
    "    'clf__scale_pos_weight': [0, 1]}\n",
    "\n",
    "# Run grid search\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search_xgb.fit(X_train_str, y_train)\n",
    "\n",
    "# Results\n",
    "best_train_cv_score_xgb = grid_search_xgb.best_score_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "y_val_pred_xgb = best_model_xgb.predict(X_val_str)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_xgb}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score_xgb:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a075f4ec-f694-4a00-b326-7532f16e18ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFitting 5 folds for each of 96 candidates, totalling 480 fits\\n\\nXGBoost Results:\\nBest Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7239\\nValidation Set Accuracy: 0.7497\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
    "\n",
    "XGBoost Results:\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7239\n",
    "Validation Set Accuracy: 0.7497\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7340b491-1881-456d-982a-439052377a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.75, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7246\n",
      "Validation Set Accuracy: 0.7374\n"
     ]
    }
   ],
   "source": [
    "# Base param grid for TF-IDF\n",
    "base_param_grid = {\n",
    "    'tfidf__max_features': [3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 2],\n",
    "    'tfidf__max_df': [0.75, 0.85, 0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list2, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "# XGBoost Pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', XGBClassifier(random_state=24, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    **base_param_grid,\n",
    "    'clf__n_estimators': [200],\n",
    "    'clf__max_depth': [5],\n",
    "    'clf__learning_rate': [0.3],  # Default is 0.3\n",
    "    'clf__scale_pos_weight': [1]}\n",
    "\n",
    "# Run grid search\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search_xgb.fit(X_train_str, y_train)\n",
    "\n",
    "# Results\n",
    "best_train_cv_score_xgb = grid_search_xgb.best_score_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "y_val_pred_xgb = best_model_xgb.predict(X_val_str)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_xgb}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score_xgb:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c2766c7-bb19-4694-8bf3-2090a5b36574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.65, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7246\n",
      "Validation Set Accuracy: 0.7374\n"
     ]
    }
   ],
   "source": [
    "# Base param grid for TF-IDF\n",
    "base_param_grid = {\n",
    "    'tfidf__max_features': [3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tfidf__min_df': [ 2, 10, 100],\n",
    "    'tfidf__max_df': [0.65, 0.75, 0.85,],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list2, stopwords_list2, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "# XGBoost Pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', XGBClassifier(random_state=24, use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    **base_param_grid,\n",
    "    'clf__n_estimators': [200],\n",
    "    'clf__max_depth': [5],\n",
    "    'clf__learning_rate': [0.3],  # Default is 0.3\n",
    "    'clf__scale_pos_weight': [1]}\n",
    "\n",
    "# Run grid search\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    pipeline_xgb,\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search_xgb.fit(X_train_str, y_train)\n",
    "\n",
    "# Results\n",
    "best_train_cv_score_xgb = grid_search_xgb.best_score_\n",
    "best_model_xgb = grid_search_xgb.best_estimator_\n",
    "y_val_pred_xgb = best_model_xgb.predict(X_val_str)\n",
    "val_accuracy_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params_xgb}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score_xgb:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ad17c00-674b-4b15-80fc-edf933bf636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nXGBoost Results:\\nBest Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.65, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7246\\nValidation Set Accuracy: 0.7374\\n\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGBoost Results:\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.3, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'clf__scale_pos_weight': 1, 'tfidf__max_df': 0.65, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7246\n",
    "Validation Set Accuracy: 0.7374\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24f498-3719-46e3-b83c-ba9b395e1bc3",
   "metadata": {},
   "source": [
    "### best xgb score train: 0.7246  val:  0.7374"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b664804-c7b7-450a-9ec4-fcb34a38f53e",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be673696-c860-4853-a309-a2f895a173d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7130\n",
      "Validation Set Accuracy: 0.7520\n"
     ]
    }
   ],
   "source": [
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "516ec0eb-a110-4b8a-9303-89a9a2e76245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7130\\nValidation Set Accuracy: 0.7520\\n\\n\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7130\n",
    "Validation Set Accuracy: 0.7520\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85bdc3b3-3ae5-4538-8bfa-8ec3ab5d670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7154\n",
      "Validation Set Accuracy: 0.7520\n"
     ]
    }
   ],
   "source": [
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000,],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.85, 0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__alpha': [0.01, 0.1, 0.5, 1.0, 2.0],\n",
    "    'clf__fit_prior': [True, False]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c05d834e-8159-4ed3-bbd4-76d0f6889830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7154\\nValidation Set Accuracy: 0.7520\\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7154\n",
    "Validation Set Accuracy: 0.7520\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c547bda-4120-49d3-bbd3-425d8e52a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__alpha': 0.01, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7148\n",
      "Validation Set Accuracy: 0.7542\n"
     ]
    }
   ],
   "source": [
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000,],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.85, 0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__alpha': [0.01, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "    'clf__fit_prior': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e7b9456-1c70-4b8e-b25b-00edfbab1ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__alpha': 0.01, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7148\\nValidation Set Accuracy: 0.7542\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__alpha': 0.01, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7148\n",
    "Validation Set Accuracy: 0.7542\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc4dcf3b-91f4-4244-b81a-7bc9bdcae5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__alpha': 0.01, 'clf__fit_prior': True, 'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7148\n",
      "Validation Set Accuracy: 0.7542\n"
     ]
    }
   ],
   "source": [
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000,],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.85, 0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__alpha': [0.01],\n",
    "    'clf__fit_prior': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d7754b-1ea5-4617-9cb8-b276b8727e90",
   "metadata": {},
   "source": [
    "### best multi NB score Train 0.7148, val 0.7542\n",
    "### best log reg score train 0.7277 val 0.7531\n",
    "### best xgb score train: 0.7246 val: 0.7374"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fa4d6-76c4-4b5e-acde-8f0096f89134",
   "metadata": {},
   "source": [
    "# linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32a80e1a-4050-473b-8f0d-b4dba26bed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7285\n",
      "Validation Set Accuracy: 0.7710\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01da30-bbc8-4309-a00c-4b321e8a86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7285\n",
    "Validation Set Accuracy: 0.7710\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ab84ac2-7aab-446f-9361-d90707029abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7285\n",
      "Validation Set Accuracy: 0.7710\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e7c4f-2a2a-4d2b-9055-a57c2bf4939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7285\n",
    "Validation Set Accuracy: 0.7710\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d22abd1a-b7d7-4aaf-a229-e8902817566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__C': 1, 'clf__loss': 'squared_hinge', 'clf__penalty': 'l2', 'clf__tol': 0.1, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7288\n",
      "Validation Set Accuracy: 0.7710\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__loss': ['hinge', 'squared_hinge'],\n",
    "    'clf__tol': [1e-4, 1e-3, 1e-2, 1e-1]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14b17754-ffa7-4273-be23-3360db5da7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBest Hyperparameters: {\\'clf__C\\': 1, \\'clf__loss\\': \\'squared_hinge\\', \\'clf__penalty\\': \\'l2\\', \\'clf__tol\\': 0.1, \\'tfidf__max_df\\': 0.95, \\'tfidf__max_features\\': 3500, \\'tfidf__min_df\\': 0.0, \\'tfidf__ngram_range\\': (1, 1), \\'tfidf__stop_words\\': [\\'a\\', \\'about\\', \\'above\\', \\'after\\', \\'again\\', \\'against\\', \\'ain\\', \\'all\\', \\'am\\', \\'an\\', \\'and\\', \\'any\\', \\'are\\', \\'aren\\', \"aren\\'t\", \\'as\\', \\'at\\', \\'be\\', \\'because\\', \\'been\\', \\'before\\', \\'being\\', \\'below\\', \\'between\\', \\'both\\', \\'but\\', \\'by\\', \\'couldn\\', \"couldn\\'t\", \\'d\\', \\'did\\', \\'didn\\', \"didn\\'t\", \\'do\\', \\'does\\', \\'doesn\\', \"doesn\\'t\", \\'doing\\', \\'don\\', \"don\\'t\", \\'down\\', \\'during\\', \\'each\\', \\'few\\', \\'for\\', \\'from\\', \\'further\\', \\'had\\', \\'hadn\\', \"hadn\\'t\", \\'has\\', \\'hasn\\', \"hasn\\'t\", \\'have\\', \\'haven\\', \"haven\\'t\", \\'having\\', \\'he\\', \"he\\'d\", \"he\\'ll\", \\'her\\', \\'here\\', \\'hers\\', \\'herself\\', \"he\\'s\", \\'him\\', \\'himself\\', \\'his\\', \\'how\\', \\'i\\', \"i\\'d\", \\'if\\', \"i\\'ll\", \"i\\'m\", \\'in\\', \\'into\\', \\'is\\', \\'isn\\', \"isn\\'t\", \\'it\\', \"it\\'d\", \"it\\'ll\", \"it\\'s\", \\'its\\', \\'itself\\', \"i\\'ve\", \\'just\\', \\'ll\\', \\'m\\', \\'ma\\', \\'me\\', \\'mightn\\', \"mightn\\'t\", \\'more\\', \\'most\\', \\'mustn\\', \"mustn\\'t\", \\'my\\', \\'myself\\', \\'needn\\', \"needn\\'t\", \\'no\\', \\'nor\\', \\'now\\', \\'o\\', \\'of\\', \\'off\\', \\'on\\', \\'once\\', \\'only\\', \\'or\\', \\'other\\', \\'our\\', \\'ours\\', \\'ourselves\\', \\'out\\', \\'over\\', \\'own\\', \\'re\\', \\'s\\', \\'same\\', \\'shan\\', \"shan\\'t\", \\'she\\', \"she\\'d\", \"she\\'ll\", \"she\\'s\", \\'should\\', \\'shouldn\\', \"shouldn\\'t\", \"should\\'ve\", \\'so\\', \\'some\\', \\'such\\', \\'t\\', \\'than\\', \\'that\\', \"that\\'ll\", \\'the\\', \\'their\\', \\'theirs\\', \\'them\\', \\'themselves\\', \\'then\\', \\'there\\', \\'these\\', \\'they\\', \"they\\'d\", \"they\\'ll\", \"they\\'re\", \"they\\'ve\", \\'this\\', \\'those\\', \\'through\\', \\'to\\', \\'too\\', \\'under\\', \\'until\\', \\'up\\', \\'ve\\', \\'very\\', \\'was\\', \\'wasn\\', \"wasn\\'t\", \\'we\\', \"we\\'d\", \"we\\'ll\", \"we\\'re\", \\'were\\', \\'weren\\', \"weren\\'t\", \"we\\'ve\", \\'what\\', \\'when\\', \\'where\\', \\'which\\', \\'while\\', \\'who\\', \\'whom\\', \\'why\\', \\'will\\', \\'with\\', \\'won\\', \"won\\'t\", \\'wouldn\\', \"wouldn\\'t\", \\'y\\', \\'you\\', \"you\\'d\", \"you\\'ll\", \\'your\\', \"you\\'re\", \\'yours\\', \\'yourself\\', \\'yourselves\\', \"you\\'ve\"], \\'tfidf__sublinear_tf\\': True, \\'tfidf__use_idf\\': True}\\nBest Train Cross-Validation Score: 0.7288\\nValidation Set Accuracy: 0.7710\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__C': 1, 'clf__loss': 'squared_hinge', 'clf__penalty': 'l2', 'clf__tol': 0.1, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7288\n",
    "Validation Set Accuracy: 0.7710\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4acaad23-7047-4b61-8dfc-9691b527e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__C': 1, 'clf__loss': 'squared_hinge', 'clf__penalty': 'l2', 'clf__tol': 0.1, 'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 0.0, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"], 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7288\n",
      "Validation Set Accuracy: 0.7710\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__C': [1,],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__loss': ['squared_hinge'],\n",
    "    'clf__tol': [1e-1]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1245a692-9e38-435f-92a2-88eab1e79ee4",
   "metadata": {},
   "source": [
    "### best multi NB score Train 0.7148, val 0.7542\n",
    "### best log reg score train 0.7277 val 0.7531\n",
    "### best xgb score train: 0.7246 val: 0.7374\n",
    "### best linear svc score train: 0.7288 val: 0.7710 current leader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0bb765-db44-4e6a-8633-93e6a7a68a13",
   "metadata": {},
   "source": [
    "# random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9c360efb-a929-4de4-948f-02a92b605657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7285\n",
      "Validation Set Accuracy: 0.7531\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f813f343-a345-4adc-9026-3067038a4875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7285\\nValidation Set Accuracy: 0.7531\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7285\n",
    "Validation Set Accuracy: 0.7531\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c56e919-542b-4f69-8524-81579740bee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 200, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7309\n",
      "Validation Set Accuracy: 0.7632\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [ 2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__max_depth': [10, 20, None],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__min_samples_leaf': [1, 2],\n",
    "    'clf__max_features': ['sqrt', 'log2', None],\n",
    "    'clf__bootstrap': [True, False]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a75b1ef5-0fe4-43af-a3c5-96057c2a7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 200, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7309\\nValidation Set Accuracy: 0.7632\\n\\n\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__n_estimators': 200, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7309\n",
    "Validation Set Accuracy: 0.7632\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69c9f152-33e0-4477-bee9-6f0ab8647b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 150, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7314\n",
      "Validation Set Accuracy: 0.7643\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [ 2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [150, 200, 250],\n",
    "    'clf__max_depth': [None],\n",
    "    'clf__min_samples_split': [5, 10],\n",
    "    'clf__min_samples_leaf': [1],\n",
    "    'clf__max_features': ['sqrt'],\n",
    "    'clf__bootstrap': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32fac9f3-9206-4403-872a-a4c9e5fb77cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 150, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7314\\nValidation Set Accuracy: 0.7643\\n\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 150, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7314\n",
    "Validation Set Accuracy: 0.7643\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed0f481e-7364-4958-9961-f28f208812d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 150, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7314\n",
      "Validation Set Accuracy: 0.7643\n"
     ]
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000],\n",
    "    'tfidf__ngram_range': [(1,2)],\n",
    "    'tfidf__min_df': [ 2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [150],\n",
    "    'clf__max_depth': [None],\n",
    "    'clf__min_samples_split': [10],\n",
    "    'clf__min_samples_leaf': [1],\n",
    "    'clf__max_features': ['sqrt'],\n",
    "    'clf__bootstrap': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a42f327d-28d9-47e8-90cb-a1d3eaff5758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 150, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7314\\nValidation Set Accuracy: 0.7643\\n\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__bootstrap': True, 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 150, 'tfidf__max_df': 0.95, 'tfidf__max_features': 2000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7314\n",
    "Validation Set Accuracy: 0.7643\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc26e47-938c-4b23-bf0c-b113e08cce39",
   "metadata": {},
   "source": [
    "### best multi NB score Train 0.7148, val 0.7542\n",
    "### best log reg score train 0.7277 val 0.7531\n",
    "### best xgb score train: 0.7246 val: 0.7374\n",
    "### best linear svc score train: 0.7288 val: 0.7710 current leader\n",
    "### best random forest score train: 0.7314  val: 0.7643"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e4861-7f32-4805-a057-c015ab087bf7",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2b041a9d-35e3-4b35-a312-0ee974d7cb0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 29\u001b[0m\n\u001b[1;32m     20\u001b[0m grid_search1 \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     21\u001b[0m     pipeline1,\n\u001b[1;32m     22\u001b[0m     param_grid1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     26\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the training data\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mgrid_search1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Get the best train cross-validation score\u001b[39;00m\n\u001b[1;32m     32\u001b[0m best_train_cv_score \u001b[38;5;241m=\u001b[39m grid_search1\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b2fae57d-0990-43a5-b5b2-dda75a752173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7104\n",
      "Validation Set Accuracy: 0.7497\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 3000, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3)],\n",
    "    'tfidf__min_df': [0.0, 2, 0.01],\n",
    "    'tfidf__max_df': [0.85, 0.95, 1.0],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "262a71a3-c95c-4df8-aca5-088c859d9403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nBest Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7104\\nValidation Set Accuracy: 0.7497\\n\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7104\n",
    "Validation Set Accuracy: 0.7497\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7f1907f-0076-48df-8c9c-e79682e06d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7104\n",
      "Validation Set Accuracy: 0.7464\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97253a61-797d-40f1-b57b-93a47d4a5fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7104\\nValidation Set Accuracy: 0.7464\\n\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.95, 'tfidf__max_features': 3500, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7104\n",
    "Validation Set Accuracy: 0.7464\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c8fda1f-b3f0-4649-9872-dbdcf6d415f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__learning_rate': 0.1, 'clf__loss': 'exponential', 'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.8, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7280\n",
      "Validation Set Accuracy: 0.7587\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'clf__max_depth': [3, 4, 5],\n",
    "    'clf__subsample': [0.8, 0.9, 1.0],\n",
    "    'clf__min_samples_split': [2, 10],\n",
    "    'clf__min_samples_leaf': [1, 5],\n",
    "    'clf__loss': ['deviance', 'exponential']}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef38c25f-13e1-4820-a52e-0dc83c17b311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__learning_rate': 0.1, 'clf__loss': 'exponential', 'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.8, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7280\\nValidation Set Accuracy: 0.7587\\n\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.1, 'clf__loss': 'exponential', 'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.8, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7280\n",
    "Validation Set Accuracy: 0.7587\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "106f9e3d-720f-4f3d-ae7d-9c95786efd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__learning_rate': 0.1, 'clf__loss': 'exponential', 'clf__max_depth': 7, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.8, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7322\n",
      "Validation Set Accuracy: 0.7621\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [300, 400],\n",
    "    'clf__learning_rate': [0.1, 0.2],\n",
    "    'clf__max_depth': [5, 6, 7],\n",
    "    'clf__subsample': [0.7, 0.8],\n",
    "    'clf__min_samples_split': [2, 3, 4],\n",
    "    'clf__min_samples_leaf': [4, 5, 6],\n",
    "    'clf__loss': ['exponential']}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc3c9a-9240-427d-b3b2-a641ee50a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.1, 'clf__loss': 'exponential', 'clf__max_depth': 7, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.8, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7322\n",
    "Validation Set Accuracy: 0.7621\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cc92a3c4-3cd9-4d84-8766-378df40c2203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__learning_rate': 0.05, 'clf__loss': 'exponential', 'clf__max_depth': 9, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.85, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7334\n",
      "Validation Set Accuracy: 0.7609\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [250, 300, 350],\n",
    "    'clf__learning_rate': [0.05, 0.1, 0.15],\n",
    "    'clf__max_depth': [7, 8, 9],\n",
    "    'clf__subsample': [0.75, 0.8, 0.85, 0.9],\n",
    "    'clf__min_samples_split': [1, 2, 3],\n",
    "    'clf__min_samples_leaf': [3, 4, 5],\n",
    "    'clf__loss': ['exponential']}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a23e0-f700-44d2-a4d1-d12a575a07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__learning_rate': 0.05, 'clf__loss': 'exponential', 'clf__max_depth': 9, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.85, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7334\n",
    "Validation Set Accuracy: 0.7609\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79441b49-1f39-4528-a50c-70c0b0f6a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__learning_rate': 0.05, 'clf__loss': 'exponential', 'clf__max_depth': 9, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__subsample': 0.85, 'tfidf__max_df': 0.95, 'tfidf__max_features': 4000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7334\n",
      "Validation Set Accuracy: 0.7609\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [4000],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [2],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__n_estimators': [300],\n",
    "    'clf__learning_rate': [0.05],\n",
    "    'clf__max_depth': [9],\n",
    "    'clf__subsample': [0.85],\n",
    "    'clf__min_samples_split': [2],\n",
    "    'clf__min_samples_leaf': [4],\n",
    "    'clf__loss': ['exponential']}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e875be-cb84-4c6f-ae54-86a214cd1e30",
   "metadata": {},
   "source": [
    "### best multi NB score Train 0.7148, val 0.7542\n",
    "### best log reg score train 0.7277 val 0.7531\n",
    "### best xgb score train: 0.7246 val: 0.7374\n",
    "### best linear svc score train: 0.7288 val: 0.7710 current leader\n",
    "### best random forest score train: 0.7314 val: 0.7643\n",
    "### best gradient boosting score train: 0.7322 val: 0.7621 vs train 0.7334 val 0.7609# #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519e630-22bb-478e-b53c-34ee71f96bf5",
   "metadata": {},
   "source": [
    "# MLP Calssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "890cf75c-610a-4980-882d-4f63a98eb020",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 30\u001b[0m\n\u001b[1;32m     21\u001b[0m grid_search1 \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     22\u001b[0m     pipeline1,\n\u001b[1;32m     23\u001b[0m     param_grid1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     27\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the training data\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mgrid_search1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Get the best train cross-validation score\u001b[39;00m\n\u001b[1;32m     33\u001b[0m best_train_cv_score \u001b[38;5;241m=\u001b[39m grid_search1\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MLPClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [2000, 2500, 3000, 3500, 4000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2), (1,3), (1,5)],\n",
    "    'tfidf__min_df': [0.0, 2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list, 'english', None],\n",
    "    'tfidf__sublinear_tf': [True]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b4776-4a99-459d-b43c-d57ac04ce169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'tfidf__max_df': 0.85, 'tfidf__max_features': 2000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7115\n",
    "Validation Set Accuracy: 0.7329\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d1b99a5-77f3-4c51-bafa-7daff7ce3b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__max_iter': 500, 'tfidf__max_df': 0.85, 'tfidf__max_features': 1000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7086\n",
      "Validation Set Accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MLPClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [500, 1000, 2000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1,2)],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.85],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__max_iter': [500]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d255a86-08dd-4792-8a80-16b52728439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__max_iter': 500, 'tfidf__max_df': 0.85, 'tfidf__max_features': 1000, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7086\n",
    "Validation Set Accuracy: 0.7363\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07b70227-c058-48b6-91f8-e50b028fe4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__max_iter': 500, 'tfidf__max_df': 0.85, 'tfidf__max_features': 1250, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7131\n",
      "Validation Set Accuracy: 0.7318\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MLPClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [750, 1000, 1250],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.85],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__max_iter': [500]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f528f532-c396-41ba-a4ae-74f24452087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest Hyperparameters: {'clf__max_iter': 500, 'tfidf__max_df': 0.85, 'tfidf__max_features': 1250, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\\nBest Train Cross-Validation Score: 0.7131\\nValidation Set Accuracy: 0.7318\\n\\n\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Hyperparameters: {'clf__max_iter': 500, 'tfidf__max_df': 0.85, 'tfidf__max_features': 1250, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
    "Best Train Cross-Validation Score: 0.7131\n",
    "Validation Set Accuracy: 0.7318\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2abad948-4064-4e55-bcf7-9bf3d55d1d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'clf__activation': 'relu', 'clf__hidden_layer_sizes': (100,), 'clf__max_iter': 500, 'clf__solver': 'adam', 'tfidf__max_df': 0.85, 'tfidf__max_features': 1250, 'tfidf__min_df': 0.001, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n",
      "Best Train Cross-Validation Score: 0.7131\n",
      "Validation Set Accuracy: 0.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_py_3_8_5_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#may take too long\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MLPClassifier(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [1250],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [0.001],\n",
    "    'tfidf__max_df': [0.85],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [None],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__max_iter': [500],\n",
    "    'clf__hidden_layer_sizes': [(100,)],\n",
    "    'clf__activation': ['relu'],\n",
    "    'clf__solver': ['adam']}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab02054-fbbc-4e9d-9cd9-95040c6346e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d28cfe2-ede4-4327-b9df-e24719f93c38",
   "metadata": {},
   "source": [
    "### best multi NB score Train 0.7148, val 0.7542\n",
    "### best log reg score train 0.7277 val 0.7531\n",
    "### best xgb score train: 0.7246 val: 0.7374\n",
    "### best linear svc score train: 0.7288 val: 0.7710 current leader\n",
    "### best random forest score train: 0.7314 val: 0.7643\n",
    "### best gradient boosting score train: 0.7322 val: 0.7621 vs train 0.7334 val 0.7609# #\n",
    "### best mlp classifier score train: 0.7131 val: 0.7318"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba62da1-0f57-481a-a098-4cdfa5bab369",
   "metadata": {},
   "source": [
    "# best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aa7629fe-a745-443c-9aed-994a313be601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train Cross-Validation Score: 0.7288\n",
      "Validation Set Accuracy: 0.7710\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSbUlEQVR4nO3deVyVZf7/8ddhXw8KCkcUcUuFRE1rFC1zS1zGtPy2SYqN6U8HKy0dc8aFtMSsJrMxbcpxmZGxsrJcyi3FUmzUREmN1FwTpFxAdFjP/fuDPM1JNPCwSOf9fDyux8P7vq/rvj+HTvLxc133fZsMwzAQERERcWIu1R2AiIiISHVTQiQiIiJOTwmRiIiIOD0lRCIiIuL0lBCJiIiI01NCJCIiIk5PCZGIiIg4PbfqDkAqn9Vq5fTp0/j7+2Mymao7HBERKQfDMLh48SKhoaG4uFReHSMvL4+CggKHz+Ph4YGXl1cFRFS1lBA5gdOnTxMWFlbdYYiIiANOnjxJgwYNKuXceXl5NA73IzOr2OFzWSwWjh49WuOSIiVETsDf3x+A4181wuynWVL5bbqveVR1hyBSKYoo5AvW2v4urwwFBQVkZhVzfHcjzP43/nsi56KV8PbHKCgoUEIkN58r02RmPxeHvugiNzM3k3t1hyBSOX56wVZVLHnw8zfh53/j17FSc5dlKCESERERAIoNK8UOvOG02LBWXDBVTAmRiIiIAGDFwMqNZ0SOjK1umj8RERERp6cKkYiIiABgxYojk16Oja5eSohEREQEgGLDoNi48WkvR8ZWN02ZiYiIiNNThUhEREQA515UrYRIREREgJKEpthJEyJNmYmIiIjTU4VIREREAE2ZiYiIiOguMxEREZGqlpCQgMlksmstW7a0Hc/LyyM+Pp6goCD8/PwYNGgQZ86csTvHiRMn6NevHz4+PgQHBzNhwgSKiorKHYsqRCIiIgKA9afmyPjyuvXWW9m4caNt283t59Rk3LhxrFmzhvfee4+AgADGjBnD/fffz7Zt2wAoLi6mX79+WCwWtm/fTkZGBkOHDsXd3Z2ZM2eWKw4lRCIiIgJAsYN3md3IWDc3NywWy1X7s7OzWbhwIUlJSXTv3h2ARYsWERERwY4dO+jYsSPr16/nwIEDbNy4kZCQENq2bcuMGTOYOHEiCQkJeHh4lDkOTZmJiIgIAMWG4w0gJyfHruXn51/zmocOHSI0NJQmTZoQGxvLiRMnANi9ezeFhYX07NnT1rdly5Y0bNiQlJQUAFJSUoiKiiIkJMTWJyYmhpycHPbv31+uz66ESERERCpUWFgYAQEBtpaYmFhqvw4dOrB48WI+/fRT5s+fz9GjR7nrrru4ePEimZmZeHh4UKtWLbsxISEhZGZmApCZmWmXDF05fuVYeWjKTERERICKW0N08uRJzGazbb+np2ep/fv06WP7c+vWrenQoQPh4eG8++67eHt7OxBJ+alCJCIiIgBYMVHsQLNiAsBsNtu1ayVEv1SrVi2aN2/O4cOHsVgsFBQUcOHCBbs+Z86csa05slgsV911dmW7tHVJ16OESERERG4Kubm5HDlyhHr16tG+fXvc3d3ZtGmT7Xh6ejonTpwgOjoagOjoaNLS0sjKyrL12bBhA2azmcjIyHJdW1NmIiIiAoDVKGmOjC+P8ePH079/f8LDwzl9+jTTpk3D1dWVRx55hICAAIYPH87TTz9NYGAgZrOZJ554gujoaDp27AhAr169iIyMZMiQIcyePZvMzEwmT55MfHx8matSVyghEhEREQDb1Jcj48vj1KlTPPLII5w9e5a6dety5513smPHDurWrQvAq6++iouLC4MGDSI/P5+YmBjeeOMN23hXV1dWr17N6NGjiY6OxtfXl7i4OKZPn17u2E2GUYOfsy1lkpOTQ0BAAOe/bYLZX7Ok8tsUE9q2ukMQqRRFRiFb+Ijs7Gy7hcoV6crviS/3W/Bz4PdE7kUrHW7NrNRYK4sqRCIiIgJUfYXoZqKESERERACwGiasxo0nNY6MrW6aPxERERGnpwqRiIiIAJoyExEREaEYF4odmDwqrsBYqpoSIhEREQHAcHANkaE1RCIiIiI1lypEIiIiAmgNkYiIiAjFhgvFhgNriGrwo541ZSYiIiJOTxUiERERAcCKCasDtRIrNbdEpIRIREREAOdeQ6QpMxEREXF6qhCJiIgIUBGLqjVlJiIiIjVcyRoiB17uqikzERERkZpLFSIREREBwOrgu8x0l5mIiIjUeFpDJCIiIk7PiovTPodIa4hERETE6alCJCIiIgAUGyaKDQcezOjA2OqmhEhEREQAKHZwUXWxpsxEREREai5ViERERAQAq+GC1YG7zKy6y0xERERqOk2ZiYiIiDgxVYhEREQEACuO3SlmrbhQqpwSIhEREQEq4sGMNXfiqeZGLiIiIlJBVCESERERoCLeZVZz6yxKiERERAQAKyasOLKGSE+qFhERkRrOmStENTdyERER+U2ZNWsWJpOJsWPH2vZ17doVk8lk10aNGmU37sSJE/Tr1w8fHx+Cg4OZMGECRUVF5bq2KkQiIiICVMSDGW987M6dO3nzzTdp3br1VcdGjBjB9OnTbds+Pj4/X7O4mH79+mGxWNi+fTsZGRkMHToUd3d3Zs6cWebrq0IkIiIiAFgNk8PtRuTm5hIbG8tbb71F7dq1rzru4+ODxWKxNbPZbDu2fv16Dhw4wL/+9S/atm1Lnz59mDFjBvPmzaOgoKDMMSghEhERkQqVk5Nj1/Lz86/bPz4+nn79+tGzZ89Sjy9btow6derQqlUrJk2axOXLl23HUlJSiIqKIiQkxLYvJiaGnJwc9u/fX+aYNWUmIiIiQMmDFR2Z9rryYMawsDC7/dOmTSMhIaHUMcuXL+err75i586dpR4fPHgw4eHhhIaGsm/fPiZOnEh6ejoffPABAJmZmXbJEGDbzszMLHPsSohEREQEqIi33ZeMPXnypN20lqenZ6n9T548yVNPPcWGDRvw8vIqtc/IkSNtf46KiqJevXr06NGDI0eO0LRp0xuO9Zc0ZSYiIiIVymw227VrJUS7d+8mKyuLdu3a4ebmhpubG8nJycydOxc3NzeKi4uvGtOhQwcADh8+DIDFYuHMmTN2fa5sWyyWMseshEhEREQAKMbkcCuPHj16kJaWRmpqqq3dfvvtxMbGkpqaiqur61VjUlNTAahXrx4A0dHRpKWlkZWVZeuzYcMGzGYzkZGRZY5FU2YiIiICVNyUWVn5+/vTqlUru32+vr4EBQXRqlUrjhw5QlJSEn379iUoKIh9+/Yxbtw4unTpYrs9v1evXkRGRjJkyBBmz55NZmYmkydPJj4+/pqVqdIoIRIREZGbkoeHBxs3bmTOnDlcunSJsLAwBg0axOTJk219XF1dWb16NaNHjyY6OhpfX1/i4uLsnltUFkqIREREBIBiKPe01y/HO2rLli22P4eFhZGcnPyrY8LDw1m7dq1D11VCJCIiIkDVT5ndTJQQiYiICKCXu4qIiIg4NVWIREREBAADE1YH1hAZDoytbkqIREREBNCUmYiIiIhTU4VIREREALAaJqzGjU97OTK2uikhEhEREQCKHXzbvSNjq1vNjVxERESkgqhCJCIiIoCmzERERESw4oLVgckjR8ZWt5obuYiIiEgFUYVIREREACg2TBQ7MO3lyNjqpoRIREREAK0hEhEREcFw8G33hp5ULSIiIlJzqUIkIiIiABRjotiBF7Q6Mra6KSESERERAKyGY+uArEYFBlPFNGUmIiIiTk8VIpEy+OfLFv71V4vdvgZN81j4+TfknHflny9b+CrZn6zTHgQEFtGpdzZxf8rA12y19X9jcn327/TleLoXYc3ymb8xvao/hkiZubgYPPpMJj0GXaB23ULOnnFnw7uBJM0Jhp+mRWrVKWT4XzJof/dFfAOK+XqHH/Mm1+f0Uc/qDV5umNXBRdWOjK1uSogqUEJCAitXriQ1NfWafY4dO0bjxo3Zs2cPbdu2rbLYxHHhLf7LrHeO2LZdXUtqw+fOuHP2jDsjpp6mYfM8sk55MPfZBpw9486Ut47ZnSPm4XN8s8eHowe8qzJ0kXJ7MD6L38ed5eWnGnI83Ytb2lzmmVdPcumiCx8trAsYTPvHMYqLTCQ81pjLuS7cP/IHZr1zhBF3tyD/v67V/RHkBlgxYXVgHZAjY6tbtaZyw4YNw2QyMWvWLLv9K1euxGQq3w+1UaNGzJkzp0z9TCYTJpMJX19f2rVrx3vvvVeua13L+PHj2bRpk2172LBhDBw40K5PWFgYGRkZtGrVqkKuKVXH1RUCg4tsLSCoGIBGLfOY+vYxOvbKIbRRAW3vzGXYxAy+3GCmuOjn8X98/nvufexH6jUsqKZPIFJ2kbdfImVdAP/ZZObMKQ++WFOLr5L9adH2MgD1mxQQeftlXn+2Ad/u9eHUES9ef7YBnl4G3e67UL3Bi9yAaq9teXl58eKLL3L+/Pkqu+b06dPJyMhgz5493HHHHTz00ENs377d4fP6+fkRFBR03T6urq5YLBbc3FScq2m+P+rBI7fdSlzHCGbFNyTrlPs1+17KccXHz4qr/jNLDXVgly9t77xI/Sb5ADSJ/C+3/u4SOz8zA+DuUTIdXJD/8z9eDcNEYYGJW++4VPUBS4W48qRqR1pNVe0JUc+ePbFYLCQmJl633/vvv8+tt96Kp6cnjRo14pVXXrEd69q1K8ePH2fcuHG26s/1+Pv7Y7FYaN68OfPmzcPb25tVq1YBkJaWRvfu3fH29iYoKIiRI0eSm5trG7tlyxZ+97vf4evrS61atejcuTPHjx8HSqbMrkyDJSQksGTJEj766CNbTFu2bOHYsWOYTCZSU1OxWq00aNCA+fPn28W3Z88eXFxcbOe9cOECjz/+OHXr1sVsNtO9e3f27t1bth+wVIiW7S4xfs4JXlh2hCdmnSLzhCfP3HcLl3Ov/l8o+6wrSXMs9Hn0x2qIVKRivPO3YJI/qsXbW79hzfG9zFv/LR++VYfNH9YG4ORhL86ccucPkzLwCyjCzd3Kg/FZ1A0tJDCksJqjlxt1ZQ2RI62mqvbIXV1dmTlzJq+//jqnTp0qtc/u3bt58MEHefjhh0lLSyMhIYEpU6awePFiAD744AMaNGhgq/xkZGSU+fpubm64u7tTUFDApUuXiImJoXbt2uzcuZP33nuPjRs3MmbMGACKiooYOHAgd999N/v27SMlJYWRI0eWmoCNHz+eBx98kN69e9ti6tSpk10fFxcXHnnkEZKSkuz2L1u2jM6dOxMeHg7AAw88QFZWFp988gm7d++mXbt29OjRg3PnzpX6mfLz88nJybFr4pg7ul+kS/9smkTmcXvXizz/r+/IzXFl68e17PpduujClKFNaNg8jyHPZFZPsCIVoMu9F+h+/wVmxTckPqY5Lz8Vxv+N+oGeD5T8vVNcZGL68EbUb5rP+wf38/GRNNp0yuU/m/wxrDW3SiDO66Yo6N933320bduWadOmsXDhwquO//Wvf6VHjx5MmTIFgObNm3PgwAFeeuklhg0bRmBgIK6urrbKT1kVFBTwyiuvkJ2dTffu3UlKSiIvL4+lS5fi6+sLwN/+9jf69+/Piy++iLu7O9nZ2fz+97+nadOmAERERJR6bj8/P7y9vcnPz79uTLGxsbzyyiucOHGChg0bYrVaWb58OZMnTwbgiy++4D//+Q9ZWVl4epbcufHyyy+zcuVKVqxYwciRI686Z2JiIs8991yZfw5Sfn4BxTRoks/pYz/fTXM514W/DG6Kt6+VaQuP4nbtGTWRm96IKRk/VYlKKkLHvvEmuEEhDz+Rxcb3AgE4nObDH+9pgY9/Me7uBtnn3Hht9SG+3aebBmoqKw6+y0yLqh334osvsmTJEg4ePHjVsYMHD9K5c2e7fZ07d+bQoUMUFxeX+1oTJ07Ez88PHx8fXnzxRWbNmkW/fv04ePAgbdq0sSVDV65jtVpJT08nMDCQYcOGERMTQ//+/XnttdfKVY0qTdu2bYmIiLBViZKTk8nKyuKBBx4AYO/eveTm5hIUFISfn5+tHT16lCNHjpR6zkmTJpGdnW1rJ0+edChGudp/L7lw+rgHgcElUwOXLrrw50ea4u5h8Nzi7/DwqsFPJxMBPL2sGFb7fdZiMJmu/m5fvuhK9jk3Qhvnc0uby6SsC6iiKKWiGT/dZXajzajBCdFNUSEC6NKlCzExMUyaNIlhw4ZV6rUmTJjAsGHD8PPzIyQkpFx3tC1atIgnn3ySTz/9lHfeeYfJkyezYcMGOnbseMPxxMbGkpSUxLPPPktSUhK9e/e2Lc7Ozc2lXr16bNmy5apxtWrVKvV8np6etmqSVIy/PxdKx17ZBDco5GymG/98uR6uLtD1vvO2ZCj/vy786fWjXM515fJPy84Cgopw/enu4++PepB3yZVzP7hRkGfiyNcl/4pu2DwPdw8lUHJz2bHBzMNPZpH1vQfH071o2uq/3P//fmD98kBbn7t+f4Hss25kfe9O44g8Rk3/npRPA/gq2b8aIxdH6G33N4lZs2bRtm1bWrRoYbc/IiKCbdu22e3btm0bzZs3x/Wn3zYeHh5lrhbVqVOHZs2aXbU/IiKCxYsXc+nSJVuVaNu2bbi4uNjFdNttt3HbbbcxadIkoqOjSUpKKjUhKmtMgwcPZvLkyezevZsVK1awYMEC27F27dqRmZmJm5sbjRo1KtPnk4r3Y4Y7iX9sxMXzrgQEFXHrHZeYs/pbagUVs3e7H998VfJ9eaxTpN24JV8ewBJWcpv9nPEN2ZfiZzv2x14truojcrN4Y3J94v6UyZjEU9QKKuLsGXfW/jOIZa+G2PoEhhTy/xJOU6tOEeey3Nj4Xm2S5oRc56wiN6+bKiGKiooiNjaWuXPn2u1/5plnuOOOO5gxYwYPPfQQKSkp/O1vf+ONN96w9WnUqBFbt27l4YcfxtPTkzp16pT7+rGxsUybNo24uDgSEhL44YcfeOKJJxgyZAghISEcPXqUv//979x7772EhoaSnp7OoUOHGDp0aKnna9SoEevWrSM9PZ2goCACAkovIzdq1IhOnToxfPhwiouLuffee23HevbsSXR0NAMHDmT27Nk0b96c06dPs2bNGu677z5uv/32cn9OKb8/Lzh+zWNtOuWy7nTqr57jpfcPV2BEIpXrv5dcWTCtPgum1b9mn48W1v3pIY3yW+HMT6q+6SKfPn06Vqv9xHW7du149913Wb58Oa1atWLq1KlMnz7dbmpt+vTpHDt2jKZNm1K37o39D+rj48O6des4d+4cd9xxB//3f/9Hjx49+Nvf/mY7/s033zBo0CCaN2/OyJEjiY+P5//9v/9X6vlGjBhBixYtuP3226lbt+5VVa7/FRsby969e7nvvvvw9v55QaLJZGLt2rV06dKFxx57jObNm/Pwww9z/PhxQkL0LzEREak4V6bMHGk1lckwDC1e+I3LyckhICCA8982wex/0+XAIhUiJrRtdYcgUimKjEK28BHZ2dmYzeZKucaV3xMD1v8Bd1+PGz5P4aUCPur1j0qNtbLot6OIiIgAOHSHmaPvQYOStcQmk4mxY8fa9uXl5REfH2+723rQoEGcOXPGbtyJEyfo168fPj4+BAcHM2HCBIqKiigPJUQiIiICVO+U2c6dO3nzzTdp3bq13f5x48axatUq3nvvPZKTkzl9+jT333+/7XhxcTH9+vWjoKCA7du3s2TJEhYvXszUqVPLdX0lRCIiIlKtcnNziY2N5a233qJ27dq2/dnZ2SxcuJC//vWvdO/enfbt27No0SK2b9/Ojh07AFi/fj0HDhzgX//6F23btqVPnz7MmDGDefPmUVBQ9jt4lRCJiIgIUHEVol++Pio/P/+6142Pj6dfv3707NnTbv/u3bspLCy029+yZUsaNmxISkoKACkpKURFRdndaBQTE0NOTg779+8v82dXQiQiIiJAxSVEYWFhBAQE2Nr1XuC+fPlyvvrqq1L7ZGZm4uHhcdWDiENCQsjMzLT1+eVd11e2r/Qpi5vqOUQiIiJS8508edLuLrNrvT3h5MmTPPXUU2zYsAEvL6+qCq9UqhCJiIgIUHEVIrPZbNeulRDt3r2brKws2rVrh5ubG25ubiQnJzN37lzc3NwICQmhoKCACxcu2I07c+aM7cXpFovlqrvOrmyX54XvSohEREQEAAPHbr0v74MNe/ToQVpaGqmpqbZ2++23Exsba/uzu7s7mzZtso1JT0/nxIkTREdHAxAdHU1aWhpZWVm2Phs2bMBsNhMZGXnVNa9FU2YiIiICVP3LXf39/WnVqpXdPl9fX4KCgmz7hw8fztNPP01gYCBms5knnniC6Oho2ztEe/XqRWRkJEOGDGH27NlkZmYyefJk4uPjy/WicyVEIiIictN69dVXcXFxYdCgQeTn5xMTE2P3LlNXV1dWr17N6NGjiY6OxtfXl7i4OKZPn16u6yghEhEREaDqK0Sl2bJli922l5cX8+bNY968edccEx4eztq1ax26rhIiERERAW6OhKi6aFG1iIiIOD1ViERERARw7gqREiIREREBwDBMGA4kNY6MrW6aMhMRERGnpwqRiIiIAD8/lNGR8TWVEiIREREBnHsNkabMRERExOmpQiQiIiKAcy+qVkIkIiIigHNPmSkhEhEREcC5K0RaQyQiIiJOTxUiERERAUoqPI5Me9XkCpESIhEREQHAAAzDsfE1labMRERExOmpQiQiIiJAyZOmTXpStYiIiDgz3WUmIiIi4sRUIRIRERGg5MGKJj2YUURERJyZYTh4l1kNvs1MU2YiIiLi9FQhEhEREcC5F1UrIRIRERFACZGIiIiIUy+q1hoiERERcXqqEImIiAjg3HeZKSESERER4EpC5MgaogoMpoppykxEREScnipEIiIiAuguMxERERGMn5oj42sqTZmJiIiI01OFSERERADnnjJThUhERERKGBXQymH+/Pm0bt0as9mM2WwmOjqaTz75xHa8a9eumEwmuzZq1Ci7c5w4cYJ+/frh4+NDcHAwEyZMoKioqNwfXRUiERERKeFghYhyjm3QoAGzZs3illtuwTAMlixZwoABA9izZw+33norACNGjGD69Om2MT4+PrY/FxcX069fPywWC9u3bycjI4OhQ4fi7u7OzJkzyxWLEiIRERGpUDk5OXbbnp6eeHp6XtWvf//+dtsvvPAC8+fPZ8eOHbaEyMfHB4vFUup11q9fz4EDB9i4cSMhISG0bduWGTNmMHHiRBISEvDw8ChzzJoyExEREeDnJ1U70gDCwsIICAiwtcTExF+9dnFxMcuXL+fSpUtER0fb9i9btow6derQqlUrJk2axOXLl23HUlJSiIqKIiQkxLYvJiaGnJwc9u/fX67PrgqRiIiIABW3qPrkyZOYzWbb/tKqQ1ekpaURHR1NXl4efn5+fPjhh0RGRgIwePBgwsPDCQ0NZd++fUycOJH09HQ++OADADIzM+2SIcC2nZmZWa7YlRCJiIhIhbqySLosWrRoQWpqKtnZ2axYsYK4uDiSk5OJjIxk5MiRtn5RUVHUq1ePHj16cOTIEZo2bVqhMWvKTEREREoYJsdbOXl4eNCsWTPat29PYmIibdq04bXXXiu1b4cOHQA4fPgwABaLhTNnztj1ubJ9rXVH16KESERERICKW0PkCKvVSn5+fqnHUlNTAahXrx4A0dHRpKWlkZWVZeuzYcMGzGazbdqtrDRlJiIiItVi0qRJ9OnTh4YNG3Lx4kWSkpLYsmUL69at48iRIyQlJdG3b1+CgoLYt28f48aNo0uXLrRu3RqAXr16ERkZyZAhQ5g9ezaZmZlMnjyZ+Pj4665bKo0SIhERESlRxS8zy8rKYujQoWRkZBAQEEDr1q1Zt24d99xzDydPnmTjxo3MmTOHS5cuERYWxqBBg5g8ebJtvKurK6tXr2b06NFER0fj6+tLXFyc3XOLykoJkYiIiABV/+qOhQsXXvNYWFgYycnJv3qO8PBw1q5dW67rlqZMCdHHH39c5hPee++9NxyMiIiISHUoU0I0cODAMp3MZDJRXFzsSDwiIiJSnSpgYXRNVKaEyGq1VnYcIiIiUs30tvsblJeXV1FxiIiISHWr4rfd30zKnRAVFxczY8YM6tevj5+fH9999x0AU6ZMue7iKBEREZGbVbkTohdeeIHFixcze/Zsu7fItmrVirfffrtCgxMREZGqZKqAVjOVOyFaunQpf//734mNjcXV1dW2v02bNnzzzTcVGpyIiIhUIU2Zld33339Ps2bNrtpvtVopLCyskKBEREREqlK5E6LIyEg+//zzq/avWLGC2267rUKCEhERkWrgxBWicj+peurUqcTFxfH9999jtVr54IMPSE9PZ+nSpaxevboyYhQREZGqcINvrLcbX0OVu0I0YMAAVq1axcaNG/H19WXq1KkcPHiQVatWcc8991RGjCIiIiKV6obeZXbXXXexYcOGio5FREREqpFhlDRHxtdUN/xy1127dnHw4EGgZF1R+/btKywoERERqQZV/Lb7m0m5E6JTp07xyCOPsG3bNmrVqgXAhQsX6NSpE8uXL6dBgwYVHaOIiIhIpSr3GqLHH3+cwsJCDh48yLlz5zh37hwHDx7EarXy+OOPV0aMIiIiUhWuLKp2pNVQ5a4QJScns337dlq0aGHb16JFC15//XXuuuuuCg1OREREqo7JKGmOjK+pyp0QhYWFlfoAxuLiYkJDQyskKBEREakGTryGqNxTZi+99BJPPPEEu3btsu3btWsXTz31FC+//HKFBiciIiJSFcpUIapduzYm08/zgpcuXaJDhw64uZUMLyoqws3NjT/84Q8MHDiwUgIVERGRSubED2YsU0I0Z86cSg5DREREqp0TT5mVKSGKi4ur7DhEREREqs0NP5gRIC8vj4KCArt9ZrPZoYBERESkmjhxhajci6ovXbrEmDFjCA4OxtfXl9q1a9s1ERERqaGc+G335U6I/vSnP/HZZ58xf/58PD09efvtt3nuuecIDQ1l6dKllRGjiIiISKUq95TZqlWrWLp0KV27duWxxx7jrrvuolmzZoSHh7Ns2TJiY2MrI04RERGpbE58l1m5K0Tnzp2jSZMmQMl6oXPnzgFw5513snXr1oqNTkRERKrMlSdVO9JqqnInRE2aNOHo0aMAtGzZknfffRcoqRxdedmriIiISE1S7oToscceY+/evQA8++yzzJs3Dy8vL8aNG8eECRMqPEARERGpIk68qLrca4jGjRtn+3PPnj355ptv2L17N82aNaN169YVGpyIiIhIVXDoOUQA4eHhhIeHV0QsIiIiUo1MOPi2+wqLpOqVKSGaO3dumU/45JNP3nAwIiIiItWhTAnRq6++WqaTmUwmJUQ3sf/r1A03F4/qDkOkUhid61d3CCKVwijKgx0fVdHFdNv9dR09erRM7bvvvqvseEVERKSyVPGi6vnz59O6dWvMZjNms5no6Gg++eQT2/G8vDzi4+MJCgrCz8+PQYMGcebMGbtznDhxgn79+uHj40NwcDATJkygqKio3B+93HeZiYiIiFSEBg0aMGvWLHbv3s2uXbvo3r07AwYMYP/+/UDJjVyrVq3ivffeIzk5mdOnT3P//ffbxhcXF9OvXz8KCgrYvn07S5YsYfHixUydOrXcsTi8qFpERER+Iyro5a45OTl2uz09PfH09Lyqe//+/e22X3jhBebPn8+OHTto0KABCxcuJCkpie7duwOwaNEiIiIi2LFjBx07dmT9+vUcOHCAjRs3EhISQtu2bZkxYwYTJ04kISEBD4+yLxNRhUhERESAintSdVhYGAEBAbaWmJj4q9cuLi5m+fLlXLp0iejoaHbv3k1hYSE9e/a09WnZsiUNGzYkJSUFgJSUFKKioggJCbH1iYmJIScnx1ZlKitViERERKRCnTx5ErPZbNsurTp0RVpaGtHR0eTl5eHn58eHH35IZGQkqampeHh4XPUWjJCQEDIzMwHIzMy0S4auHL9yrDyUEImIiEiJCpoyu7JIuixatGhBamoq2dnZrFixgri4OJKTkx0I4sbc0JTZ559/zqOPPkp0dDTff/89AP/85z/54osvKjQ4ERERqULV8OoODw8PmjVrRvv27UlMTKRNmza89tprWCwWCgoKuHDhgl3/M2fOYLFYALBYLFfddXZl+0qfsip3QvT+++8TExODt7c3e/bsIT8/H4Ds7GxmzpxZ3tOJiIiI2FitVvLz82nfvj3u7u5s2rTJdiw9PZ0TJ04QHR0NQHR0NGlpaWRlZdn6bNiwAbPZTGRkZLmuW+6E6Pnnn2fBggW89dZbuLu72/Z37tyZr776qrynExERkZtERS2qLqtJkyaxdetWjh07RlpaGpMmTWLLli3ExsYSEBDA8OHDefrpp9m8eTO7d+/mscceIzo6mo4dOwLQq1cvIiMjGTJkCHv37mXdunVMnjyZ+Pj4665bKk251xClp6fTpUuXq/YHBARcVdYSERGRGqSKn1SdlZXF0KFDycjIICAggNatW7Nu3TruueceoORNGS4uLgwaNIj8/HxiYmJ44403bONdXV1ZvXo1o0ePJjo6Gl9fX+Li4pg+fXq5Qy93QmSxWDh8+DCNGjWy2//FF1/QpEmTcgcgIiIiN4kKWlRdVgsXLrzucS8vL+bNm8e8efOu2Sc8PJy1a9eW78KlKPeU2YgRI3jqqaf48ssvMZlMnD59mmXLljF+/HhGjx7tcEAiIiIiVa3cFaJnn30Wq9VKjx49uHz5Ml26dMHT05Px48fzxBNPVEaMIiIiUgVuZB3QL8fXVOVOiEwmE3/5y1+YMGEChw8fJjc3l8jISPz8/CojPhEREakqVTxldjO54Qczenh4lPuWNhEREZGbUbkTom7dumEyXXsV+WeffeZQQCIiIlJNHJwyc6oKUdu2be22CwsLSU1N5euvvyYuLq6i4hIREZGqpimzsnv11VdL3Z+QkEBubq7DAYmIiIhUtRt6l1lpHn30Uf7xj39U1OlERESkqlXDu8xuFhX2tvuUlBS8vLwq6nQiIiJSxXTbfTncf//9dtuGYZCRkcGuXbuYMmVKhQUmIiIiUlXKnRAFBATYbbu4uNCiRQumT59Or169KiwwERERkapSroSouLiYxx57jKioKGrXrl1ZMYmIiEh1cOK7zMq1qNrV1ZVevXrprfYiIiK/QVfWEDnSaqpy32XWqlUrvvvuu8qIRURERKRalDshev755xk/fjyrV68mIyODnJwcuyYiIiI1mBPecg/lWEM0ffp0nnnmGfr27QvAvffea/cKD8MwMJlMFBcXV3yUIiIiUvmceA1RmROi5557jlGjRrF58+bKjEdERESkypU5ITKMkrTv7rvvrrRgREREpProwYxldL233IuIiEgNpymzsmnevPmvJkXnzp1zKCARERGRqlauhOi555676knVIiIi8tugKbMyevjhhwkODq6sWERERKQ6OfGUWZmfQ6T1QyIiIvJbVe67zEREROQ3yokrRGVOiKxWa2XGISIiItVMa4hEREREnLhCVO53mYmIiIj81qhCJCIiIiWcuEKkhEhEREQA515DpCkzERERcXqqEImIiEgJJ54yU4VIREREgJ+nzBxp5ZGYmMgdd9yBv78/wcHBDBw4kPT0dLs+Xbt2xWQy2bVRo0bZ9Tlx4gT9+vXDx8eH4OBgJkyYQFFRUbliUYVIREREqkVycjLx8fHccccdFBUV8ec//5levXpx4MABfH19bf1GjBjB9OnTbds+Pj62PxcXF9OvXz8sFgvbt28nIyODoUOH4u7uzsyZM8scixIiERERKVHFU2affvqp3fbixYsJDg5m9+7ddOnSxbbfx8cHi8VS6jnWr1/PgQMH2LhxIyEhIbRt25YZM2YwceJEEhIS8PDwKFMsmjITERGREkYFNCAnJ8eu5efnl+ny2dnZAAQGBtrtX7ZsGXXq1KFVq1ZMmjSJy5cv246lpKQQFRVFSEiIbV9MTAw5OTns37+/zB9dFSIRERGpUGFhYXbb06ZNIyEh4bpjrFYrY8eOpXPnzrRq1cq2f/DgwYSHhxMaGsq+ffuYOHEi6enpfPDBBwBkZmbaJUOAbTszM7PMMSshEhEREQBMPzVHxgOcPHkSs9ls2+/p6fmrY+Pj4/n666/54osv7PaPHDnS9ueoqCjq1atHjx49OHLkCE2bNnUgWnuaMhMREZESFTRlZjab7dqvJURjxoxh9erVbN68mQYNGly3b4cOHQA4fPgwABaLhTNnztj1ubJ9rXVHpVFCJCIiIkDV33ZvGAZjxozhww8/5LPPPqNx48a/OiY1NRWAevXqARAdHU1aWhpZWVm2Phs2bMBsNhMZGVnmWDRlJiIiItUiPj6epKQkPvroI/z9/W1rfgICAvD29ubIkSMkJSXRt29fgoKC2LdvH+PGjaNLly60bt0agF69ehEZGcmQIUOYPXs2mZmZTJ48mfj4+DJN1V2hCpGIiIiUqKAps7KaP38+2dnZdO3alXr16tnaO++8A4CHhwcbN26kV69etGzZkmeeeYZBgwaxatUq2zlcXV1ZvXo1rq6uREdH8+ijjzJ06FC75xaVhSpEIiIi8rMqfP2GYVz/YmFhYSQnJ//qecLDw1m7dq1DsahCJCIiIk5PFSIREREBbmxh9C/H11RKiERERKSE3nYvIiIi4rxUIRIRERFAU2YiIiIimjITERERcWaqEImIiAigKTMRERERp54yU0IkIiIiJZw4IdIaIhEREXF6qhCJiIgIoDVEIiIiIpoyExEREXFmqhCJiIgIACbDwGTceJnHkbHVTQmRiIiIlNCUmYiIiIjzUoVIREREAN1lJiIiIqIpMxERERFnpgqRiIiIAJoyExEREXHqKTMlRCIiIgI4d4VIa4hERETE6alCJCIiIiU0ZSYiIiJSs6e9HKEpMxEREXF6qhCJiIhICcMoaY6Mr6GUEImIiAigu8xEREREnJoqRCIiIlJCd5mJiIiIszNZS5oj42sqTZmJiIhItUhMTOSOO+7A39+f4OBgBg4cSHp6ul2fvLw84uPjCQoKws/Pj0GDBnHmzBm7PidOnKBfv374+PgQHBzMhAkTKCoqKlcsqhCJlEGrducZNOw4zSJyCAouYMbY1qRsDrYd79Qji74PnKJZxEXMtQoZ82AHvkv3tzvHrLd30fqOC3b71r5Xn789H1EVH0HkuqIiMnng3v3c0uQsQYH/JWF2N7bvbGjXJ6z+BR5/dDetI8/g6mJw/FQA01/pyg8/+tn6RDTP4rFH9tCy2Y8UW018d6w2k164h4IC/bqpEap4yiw5OZn4+HjuuOMOioqK+POf/0yvXr04cOAAvr6+AIwbN441a9bw3nvvERAQwJgxY7j//vvZtm0bAMXFxfTr1w+LxcL27dvJyMhg6NChuLu7M3PmzDLHom9oBdmyZQvdunXj/Pnz1KpV65r9GjVqxNixYxk7dmyVxSaO8/Iu5mi6H+tXhjLl1X2lHt+/pxafrwvhqYSD1zzPJyvq8683mti28/JcKyVekfLy8iziu+O1Wbe5GdMmbLnqeL2QHF6d8SmfftaMpe+05fJ/3QkPu0Bhwc/f4YjmWcz8y0aWfxjFvIW/o9jqQpPw8xhWUxV+EnFEVd9l9umnn9ptL168mODgYHbv3k2XLl3Izs5m4cKFJCUl0b17dwAWLVpEREQEO3bsoGPHjqxfv54DBw6wceNGQkJCaNu2LTNmzGDixIkkJCTg4eFRplicLiEaNmwYS5YsAcDd3Z2GDRsydOhQ/vznP+PmduM/jk6dOpGRkUFAQABQ8h917NixXLhwwa7fzp07bVmv1By7ttVh17Y61zz+2ep6AASH/ve658nPc+H8Wc8KjU2kIuxMbcDO1AbXPP7YI3v4z576vP2v2237Ms6Y7fqMitvJyrURvLMyyrbv1OmAig9WKk8FPYcoJyfHbrenpyeenr/+d192djYAgYGBAOzevZvCwkJ69uxp69OyZUsaNmxISkoKHTt2JCUlhaioKEJCQmx9YmJiGD16NPv37+e2224rU+hOlxAB9O7dm0WLFpGfn8/atWuJj4/H3d2dSZMm3fA5PTw8sFgsv9qvbt26N3wNqfm69c2kW79Mzp/14D/Jdfn33xuTryqR3ORMJoPftTvFex+1YuZfNtCs8Tkys/xY/mGUbVqtlvm/RDT/kc8+b8Krz68lNOQiJ08HsOjft7H/m5BfuYL81oSFhdltT5s2jYSEhOuOsVqtjB07ls6dO9OqVSsAMjMz8fDwuGrmJSQkhMzMTFuf/02Grhy/cqysnHJRtaenJxaLhfDwcEaPHk3Pnj35+OOPOX/+PEOHDqV27dr4+PjQp08fDh06ZBt3/Phx+vfvT+3atfH19eXWW29l7dq1QMmUmclk4sKFC2zZsoXHHnuM7OxsTCYTJpPJ9kVo1KgRc+bMAWDw4ME89NBDdrEVFhZSp04dli5dCpR8QRITE2ncuDHe3t60adOGFStWXPfz5efnk5OTY9ek+m35xMJLf2nFpMfb8+7CRnT/fQbjZ35d3WGJ/KpaAXn4eBfx0MCv2ZUayrPP38O2/zRk6vjNREWW/MKxhOQCMOTBvXyy8Rb+/EJPDn8XyItT1xNq0d9BNcWVKTNHGsDJkyfJzs62tbIUHOLj4/n6669Zvnx5JX/K0jllheiXvL29OXv2LMOGDePQoUN8/PHHmM1mJk6cSN++fTlw4ADu7u7Ex8dTUFDA1q1b8fX15cCBA/j5+V11vk6dOjFnzhymTp1qWy1fWr/Y2FgeeOABcnNzbcfXrVvH5cuXue+++4CSFfj/+te/WLBgAbfccgtbt27l0UcfpW7dutx9992lfp7ExESee+65ivrxSAX59P2fpyOOHfbj/I+eJL71FZYGl8k85VONkYlcn+mn33Lbd4XxwZpbAfjuWCCRLbL4/T3ppB2w4PJTnzUbmrN+yy0AHDkWRNuoTHp3P8Q/ktpXT/BSPhW0qNpsNmM2m6/f93+MGTOG1atXs3XrVho0+PnvSovFQkFBARcuXLCrEp05c8Y2K2OxWPjPf/5jd74rd6GVZebmCqesEF1hGAYbN25k3bp1NGzYkI8//pi3336bu+66izZt2rBs2TK+//57Vq5cCZTc1te5c2eioqJo0qQJv//97+nSpctV5/Xw8CAgIACTyYTFYsFisZSaEMXExODr68uHH35o25eUlMS9996Lv78/+fn5zJw5k3/84x/ExMTQpEkThg0bxqOPPsqbb755zc81adIku8z85MmTjv+wpMJ9k1aytiK04fXXHYlUt5yLnhQVmThx0n490IlTtQiucwmAcxe8f9r3iz7fB9j6iPySYRiMGTOGDz/8kM8++4zGjRvbHW/fvj3u7u5s2rTJti89PZ0TJ04QHR0NQHR0NGlpaWRlZdn6bNiwAbPZTGRkZJljccoK0erVq/Hz86OwsBCr1crgwYO5//77Wb16NR06dLD1CwoKokWLFhw8WHLX0JNPPsno0aNZv349PXv2ZNCgQbRu3fqG43Bzc+PBBx9k2bJlDBkyhEuXLvHRRx/ZyoWHDx/m8uXL3HPPPXbjCgoKrrtIrKyL16R6NW1xEYBzP5TtDgiR6lJU5Er6kTo0qG8/9dUgNJszP91yn5nlx4/nvGkQ+os+9XLYuad+lcUqjqnqu8zi4+NJSkrio48+wt/f37bmJyAgAG9vbwICAhg+fDhPP/00gYGBmM1mnnjiCaKjo+nYsSMAvXr1IjIykiFDhjB79mwyMzOZPHky8fHx5fpd6JQJUbdu3Zg/fz4eHh6Ehobi5ubGxx9//KvjHn/8cWJiYlizZg3r168nMTGRV155hSeeeOKGY4mNjeXuu+8mKyuLDRs24O3tTe/evQHIzS2Zk1+zZg3169v/haKEp2p5eRfZVXJC6v+XJi0ucjHbnR8yvfAzFxJcL4/AuvkANGhU8i/i8z96cP6sJ5YGl+nWN5Odn9chJ9udxrfkMnLCt6TtqsWxQ/6lXlOkKnl5FRJquWjbtgRfpEmjc1zM9eCHH/1Y8fGt/HncVtIOhLB3v4Xb235Px/anGJ8Q89MIE+991IqhD6Xy3fHaHDkWyD13HyGsfjYzXil9el9uQlX8tvv58+cD0LVrV7v9ixYtYtiwYQC8+uqruLi4MGjQIPLz84mJieGNN96w9XV1dWX16tWMHj2a6OhofH19iYuLY/r06eWKxSkTIl9fX5o1a2a3LyIigqKiIr788ks6deoEwNmzZ0lPT7cruYWFhTFq1ChGjRrFpEmTeOutt0pNiDw8PCguLv7VWDp16kRYWBjvvPMOn3zyCQ888ADu7u4AREZG4unpyYkTJ665Xkiqxi235vDiwq9s2yMnlCy23/BRPV6deisdu/7A0zMO2I4/O7tksfSy+Y1ZtqApRYUutO1wjgGxJ/HyLuaHTE+2bQzm32/Zl4dFqkvzJmd5+bl1tu1Rw3YBsH5LU16edyfb/hPO3L935OH70vjjH/7DqdNmpr/c1e4Osg/XRuLhUcyouJ34+xVw5Hhtnp1xz1W354tcYZQhgfLy8mLevHnMmzfvmn3Cw8NtNzndKKdMiEpzyy23MGDAAEaMGMGbb76Jv78/zz77LPXr12fAgAEAjB07lj59+tC8eXPOnz/P5s2biYgo/SnDjRo1Ijc3l02bNtGmTRt8fHzw8Sl94ezgwYNZsGAB3377LZs3b7bt9/f3Z/z48YwbNw6r1cqdd95JdnY227Ztw2w2ExcXV/E/CClV2q5A+rbpec3jGz8OZePHodc8/uMZLyYOv/2ax0Wq274DFno9cP2/U9ZtvoV1m2+5bp93VkbZPYdIapaqnjK7mTj1oupfWrRoEe3bt+f3v/890dHRGIbB2rVrbRWb4uJi4uPjiYiIoHfv3jRv3tyubPe/OnXqxKhRo3jooYeoW7cus2fPvuZ1Y2NjOXDgAPXr16dz5852x2bMmMGUKVNITEy0XXfNmjVXLTwTERFxmFEBrYYyGWWpV0mNlpOTQ0BAAD3qDMfNRQt45bepqLkW7spvU1FRHsk7nic7O7tct7KXx5XfE9G9p+Pm7nXD5ykqzCPl06mVGmtl0ZSZiIiIAM49ZaaESEREREpYjZLmyPgaSgmRiIiIlKigJ1XXRFpULSIiIk5PFSIREREBwISDa4gqLJKqp4RIRERESlTxk6pvJpoyExEREaenCpGIiIgAuu1eRERERHeZiYiIiDgzVYhEREQEAJNhYHJgYbQjY6ubEiIREREpYf2pOTK+htKUmYiIiDg9VYhEREQE0JSZiIiIiFPfZaaESEREREroSdUiIiIizksVIhEREQH0pGoRERERTZmJiIiIODNViERERAQAk7WkOTK+plJCJCIiIiU0ZSYiIiLivFQhEhERkRJ6MKOIiIg4O2d+dYemzERERMTpqUIkIiIiJZx4UbUSIhERESlhAI7cOl9z8yElRCIiIlJCa4hEREREqsHWrVvp378/oaGhmEwmVq5caXd82LBhmEwmu9a7d2+7PufOnSM2Nhaz2UytWrUYPnw4ubm55YpDCZGIiIiUMPh5HdENtfJf8tKlS7Rp04Z58+Zds0/v3r3JyMiwtX//+992x2NjY9m/fz8bNmxg9erVbN26lZEjR5YrDk2ZiYiISIlqWFTdp08f+vTpc90+np6eWCyWUo8dPHiQTz/9lJ07d3L77bcD8Prrr9O3b19efvllQkNDyxSHKkQiIiJSoXJycuxafn6+Q+fbsmULwcHBtGjRgtGjR3P27FnbsZSUFGrVqmVLhgB69uyJi4sLX375ZZmvoYRIRERESlgroAFhYWEEBATYWmJi4g2H1Lt3b5YuXcqmTZt48cUXSU5Opk+fPhQXFwOQmZlJcHCw3Rg3NzcCAwPJzMws83U0ZSYiIiJAxd1ldvLkScxms22/p6fnDZ/z4Ycftv05KiqK1q1b07RpU7Zs2UKPHj1u+Ly/pAqRiIiIVCiz2WzXHEmIfqlJkybUqVOHw4cPA2CxWMjKyrLrU1RUxLlz56657qg0SohERESkhEN3mDm4ILuMTp06xdmzZ6lXrx4A0dHRXLhwgd27d9v6fPbZZ1itVjp06FDm82rKTEREREpUw11mubm5tmoPwNGjR0lNTSUwMJDAwECee+45Bg0ahMVi4ciRI/zpT3+iWbNmxMTEABAREUHv3r0ZMWIECxYsoLCwkDFjxvDwww+X+Q4zUIVIREREqtGuXbu47bbbuO222wB4+umnue2225g6dSqurq7s27ePe++9l+bNmzN8+HDat2/P559/bjcNt2zZMlq2bEmPHj3o27cvd955J3//+9/LFYcqRCIiIlKiGipEXbt2xbjOuHXr1v3qOQIDA0lKSir3tf+XEiIREREpYQVMDo6voZQQiYiICKCXu4qIiIg4NVWIREREpEQ1rCG6WSghEhERkRJWA0wOJDXWmpsQacpMREREnJ4qRCIiIlJCU2YiIiIijr5+o+YmRJoyExEREaenCpGIiIiU0JSZiIiIOD2rgUPTXrrLTERERKTmUoVIREREShjWkubI+BpKCZGIiIiU0BoiERERcXpaQyQiIiLivFQhEhERkRKaMhMRERGnZ+BgQlRhkVQ5TZmJiIiI01OFSEREREpoykxEREScntUKOPAsIWvNfQ6RpsxERETE6alCJCIiIiU0ZSYiIiJOz4kTIk2ZiYiIiNNThUhERERKOPGrO5QQiYiICACGYcVw4I31joytbkqIREREpIRhOFbl0RoiERERkZpLFSIREREpYTi4hqgGV4iUEImIiEgJqxVMDqwDqsFriDRlJiIiIk5PCZGIiIiUuPJgRkdaOW3dupX+/fsTGhqKyWRi5cqVvwjJYOrUqdSrVw9vb2969uzJoUOH7PqcO3eO2NhYzGYztWrVYvjw4eTm5pYrDiVEIiIiAoBhtTrcyuvSpUu0adOGefPmlXp89uzZzJ07lwULFvDll1/i6+tLTEwMeXl5tj6xsbHs37+fDRs2sHr1arZu3crIkSPLFYfWEImIiEiFysnJsdv29PTE09Oz1L59+vShT58+pR4zDIM5c+YwefJkBgwYAMDSpUsJCQlh5cqVPPzwwxw8eJBPP/2UnTt3cvvttwPw+uuv07dvX15++WVCQ0PLFLMqRCIiIlKigqbMwsLCCAgIsLXExMQbCufo0aNkZmbSs2dP276AgAA6dOhASkoKACkpKdSqVcuWDAH07NkTFxcXvvzyyzJfSxUiERERKWE1wOT4bfcnT57EbDbbdl+rOvRrMjMzAQgJCbHbHxISYjuWmZlJcHCw3XE3NzcCAwNtfcpCCZGIiIhUKLPZbJcQ1QSaMhMREZEShlHyLKEbbhX7YEaLxQLAmTNn7PafOXPGdsxisZCVlWV3vKioiHPnztn6lIUSIhEREQHAsBoOt4rUuHFjLBYLmzZtsu3Lycnhyy+/JDo6GoDo6GguXLjA7t27bX0+++wzrFYrHTp0KPO1NGUmIiIiJQwrULVPqs7NzeXw4cO27aNHj5KamkpgYCANGzZk7NixPP/889xyyy00btyYKVOmEBoaysCBAwGIiIigd+/ejBgxggULFlBYWMiYMWN4+OGHy3yHGSghEhERkWq0a9cuunXrZtt++umnAYiLi2Px4sX86U9/4tKlS4wcOZILFy5w55138umnn+Ll5WUbs2zZMsaMGUOPHj1wcXFh0KBBzJ07t1xxmAyjBr+JTcokJyeHgIAAetQZjpuLR3WHI1IpiprXr+4QRCpFUVEeyTueJzs7u9IWKl/5PdHVdB9uJvcbPk+RUcgW48NKjbWyqEIkIiIiJaphyuxmoYTICVwpAhZZC6o5EpHKU1SU9+udRGqgoqJ84Oe/yyv1WhSCA5cporDigqliSoicwMWLFwFIPvfPao5EpBL9WN0BiFSuixcvEhAQUCnn9vDwwGKx8EXmWofPZbFY8PCoecsztIbICVitVk6fPo2/vz8mk6m6w/nNy8nJISws7KontYr8Vug7XrUMw+DixYuEhobi4lJ5T8vJy8ujoMDxmQQPDw+7Bc81hSpETsDFxYUGDRpUdxhOpyY+qVWkPPQdrzqVVRn6X15eXjUykakoejCjiIiIOD0lRCIiIuL0lBCJVDBPT0+mTZt2w293FrnZ6Tsuv0VaVC0iIiJOTxUiERERcXpKiERERMTpKSESERERp6eESOQmkJCQQNu2ba/b59ixY5hMJlJTU6skJpH/tWXLFkwmExcuXLhuv0aNGjFnzpwqiUmkIikhkhpp2LBhmEwmZs2aZbd/5cqV5X4ad1n/Am/UqBEmkwmTyYSvry/t2rXjvffeK9e1rmX8+PFs2rTJtj1s2DAGDhxo1ycsLIyMjAxatWpVIdeU36Yr/2+YTCY8PDxo1qwZ06dPp6ioyKHzdurUiYyMDNsDAhcvXkytWrWu6rdz505Gjhzp0LVEqoMSIqmxvLy8ePHFFzl//nyVXXP69OlkZGSwZ88e7rjjDh566CG2b9/u8Hn9/PwICgq6bh9XV1csFgtubnrAvFxf7969ycjI4NChQzzzzDMkJCTw0ksvOXTOK++6+rV/cNStWxcfHx+HriVSHZQQSY3Vs2dPLBYLiYmJ1+33/vvvc+utt+Lp6UmjRo145ZVXbMe6du3K8ePHGTdunO1f1dfj7++PxWKhefPmzJs3D29vb1atWgVAWloa3bt3x9vbm6CgIEaOHElubq5t7JYtW/jd736Hr68vtWrVonPnzhw/fhywnzJLSEhgyZIlfPTRR7aYtmzZYjdlZrVaadCgAfPnz7eLb8+ePbi4uNjOe+HCBR5//HHq1q2L2Wyme/fu7N27t2w/YKmxPD09sVgshIeHM3r0aHr27MnHH3/M+fPnGTp0KLVr18bHx4c+ffpw6NAh27jjx4/Tv39/ateuja+vL7feeitr15a87PN/p8y2bNnCY489RnZ2tu07mpCQANhXXAcPHsxDDz1kF1thYSF16tRh6dKlQMm7FhMTE2ncuDHe3t60adOGFStWVP4PSeQXlBBJjeXq6srMmTN5/fXXOXXqVKl9du/ezYMPPsjDDz9MWloaCQkJTJkyhcWLFwPwwQcf0KBBA1vlJyMjo8zXd3Nzw93dnYKCAi5dukRMTAy1a9dm586dvPfee2zcuJExY8YAUFRUxMCBA7n77rvZt28fKSkpjBw5stQEbPz48Tz44IO2f+VnZGTQqVMnuz4uLi488sgjJCUl2e1ftmwZnTt3Jjw8HIAHHniArKwsPvnkE3bv3k27du3o0aMH586dK/PnlJrP29ubgoIChg0bxq5du/j4449JSUnBMAz69u1LYWEhAPHx8eTn57N161bS0tJ48cUX8fPzu+p8nTp1Ys6cOZjNZtt3dPz48Vf1i42NZdWqVXb/MFi3bh2XL1/mvvvuAyAxMZGlS5eyYMEC9u/fz7hx43j00UdJTk6upJ+GyDUYIjVQXFycMWDAAMMwDKNjx47GH/7wB8MwDOPDDz80/vdrPXjwYOOee+6xGzthwgQjMjLSth0eHm68+uqrv3rN/+2Xn59vzJw50wCM1atXG3//+9+N2rVrG7m5ubb+a9asMVxcXIzMzEzj7NmzBmBs2bKl1HNPmzbNaNOmTamf74qjR48agLFnzx7DMAxjz549hslkMo4fP24YhmEUFxcb9evXN+bPn28YhmF8/vnnhtlsNvLy8uzO07RpU+PNN9/81c8rNdP/fnesVquxYcMGw9PT0xg4cKABGNu2bbP1/fHHHw1vb2/j3XffNQzDMKKiooyEhIRSz7t582YDMM6fP28YhmEsWrTICAgIuKrf//5/UlhYaNSpU8dYunSp7fgjjzxiPPTQQ4ZhGEZeXp7h4+NjbN++3e4cw4cPNx555JEb+fgiN0wVIqnxXnzxRZYsWcLBgwevOnbw4EE6d+5st69z584cOnSI4uLicl9r4sSJ+Pn54ePjw4svvsisWbPo168fBw8epE2bNvj6+tpdx2q1kp6eTmBgIMOGDSMmJob+/fvz2muvlasaVZq2bdsSERFhqxIlJyeTlZXFAw88AMDevXvJzc0lKCgIPz8/Wzt69ChHjhxx6Npyc1u9ejV+fn54eXnRp08fHnroIYYNG4abmxsdOnSw9QsKCqJFixa2/3eefPJJnn/+eTp37sy0adPYt2+fQ3G4ubnx4IMPsmzZMgAuXbrERx99RGxsLACHDx/m8uXL3HPPPXbf0aVLl+o7KlVOCZHUeF26dCEmJoZJkyZV+rUmTJhAamoqp06d4vz580ycOLHMYxctWkRKSgqdOnXinXfeoXnz5uzYscOheGJjY20JUVJSEr1797Ytzs7NzaVevXqkpqbatfT0dCZMmODQdeXm1q1bN1JTUzl06BD//e9/WbJkSZnuvnz88cf57rvvGDJkCGlpadx+++28/vrrDsUSGxvLpk2byMrKYuXKlXh7e9O7d28A21TamjVr7L6jBw4c0DoiqXJKiOQ3YdasWaxatYqUlBS7/REREWzbts1u37Zt22jevDmurq5Ayd0zZa0W1alTh2bNml11t01ERAR79+7l0qVLdtdxcXGhRYsWtn233XYbkyZNYvv27bRq1eqqNUBXlDWmwYMH8/XXX7N7925WrFhh+5c3QLt27cjMzMTNzY1mzZrZtTp16pTp80rN5OvrS7NmzWjYsKHtrsSIiAiKior48ssvbf3Onj1Leno6kZGRtn1hYWGMGjWKDz74gGeeeYa33nqr1GuU9TvaqVMnwsLCeOedd1i2bBkPPPAA7u7uAERGRuLp6cmJEyeu+o6GhYU58iMQKTclRPKbEBUVRWxsLHPnzrXb/8wzz7Bp0yZmzJjBt99+y5IlS/jb3/5mtwC0UaNGbN26le+//54ff/zxhq4fGxuLl5cXcXFxfP3112zevJknnniCIUOGEBISwtGjR5k0aRIpKSkcP36c9evXc+jQISIiIko9X6NGjdi3bx/p6en8+OOPtkWvpfXr1KkTw4cPp7i4mHvvvdd2rGfPnkRHRzNw4EDWr1/PsWPH2L59O3/5y1/YtWvXDX1OqbluueUWBgwYwIgRI/jiiy/Yu3cvjz76KPXr12fAgAEAjB07lnXr1nH06FG++uorNm/efN3vaG5uLps2beLHH3/k8uXL17z24MGDWbBgARs2bLBL2v39/Rk/fjzjxo1jyZIlHDlyhK+++orXX3+dJUuWVOwPQOTXVPciJpEbca1Fxx4eHsYvv9YrVqwwIiMjDXd3d6Nhw4bGSy+9ZHc8JSXFaN26teHp6XnV2P/1a4uv9+3bZ3Tr1s3w8vIyAgMDjREjRhgXL140DMMwMjMzjYEDBxr16tUzPDw8jPDwcGPq1KlGcXGxYRhXL6rOysoy7rnnHsPPz88AjM2bN1+1qPqKN954wwCMoUOHXhVTTk6O8cQTTxihoaGGu7u7ERYWZsTGxhonTpy45ueQmq20/zeuOHfunDFkyBAjICDA8Pb2NmJiYoxvv/3WdnzMmDFG06ZNDU9PT6Nu3brGkCFDjB9//NEwjKsXVRuGYYwaNcoICgoyAGPatGmGYZT+/8mBAwcMwAgPDzesVqvdMavVasyZM8do0aKF4e7ubtStW9eIiYkxkpOTHf5ZiJSHyTAMo/rSMREREZHqpykzERERcXpKiERERMTpKSESERERp6eESERERJyeEiIRERFxekqIRERExOkpIRIRERGnp4RIREREnJ4SIhGpEsOGDWPgwIG27a5duzJ27Ngqj2PLli2YTCYuXLhwzT4mk4mVK1eW+ZwJCQm0bdvWobiOHTuGyWQiNTXVofOIyI1RQiTixIYNG4bJZMJkMuHh4UGzZs2YPn06RUVFlX7tDz74gBkzZpSpb1mSGBERR7hVdwAiUr169+7NokWLyM/PZ+3atcTHx+Pu7s6kSZOu6ltQUICHh0eFXDcwMLBCziMiUhFUIRJxcp6enlgsFsLDwxk9ejQ9e/bk448/Bn6e5nrhhRcIDQ2lRYsWAJw8eZIHH3yQWrVqERgYyIABAzh27JjtnMXFxTz99NPUqlWLoKAg/vSnP/HL1yb+csosPz+fiRMnEhYWhqenJ82aNWPhwoUcO3aMbt26AVC7dm1MJhPDhg0DwGq1kpiYSOPGjfH29qZNmzasWLHC7jpr166lefPmeHt7061bN7s4y2rixIk0b94cHx8fmjRpwpQpUygsLLyq35tvvklYWBg+Pj48+OCDZGdn2x1/++23iYiIwMvLi5YtW/LGG2+UOxYRqRxKiETEjre3NwUFBbbtTZs2kZ6ezoYNG1i9ejWFhYXExMTg7+/P559/zrZt2/Dz86N37962ca+88gqLFy/mH//4B1988QXnzp3jww8/vO51hw4dyr///W/mzp3LwYMHefPNN/Hz8yMsLIz3338fgPT0dDIyMnjttdcASExMZOnSpSxYsID9+/czbtw4Hn30UZKTk4GSxO3++++nf//+pKam8vjjj/Pss8+W+2fi7+/P4sWLOXDgAK+99hpvvfUWr776ql2fw4cP8+6777Jq1So+/fRT9uzZwx//+Efb8WXLljF16lReeOEFDh48yMyZM5kyZQpLliwpdzwiUgkMEXFacXFxxoABAwzDMAyr1Wps2LDB8PT0NMaPH287HhISYuTn59vG/POf/zRatGhhWK1W2778/HzD29vbWLdunWEYhlGvXj1j9uzZtuOFhYVGgwYNbNcyDMO4++67jaeeesowDMNIT083AGPDhg2lxrl582YDMM6fP2/bl5eXZ/j4+Bjbt2+36zt8+HDjkUceMQzDMCZNmmRERkbaHZ84ceJV5/olwPjwww+vefyll14y2rdvb9ueNm2a4erqapw6dcq275NPPjFcXFyMjIwMwzAMo2nTpkZSUpLdeWbMmGFER0cbhmEYR48eNQBjz54917yuiFQerSEScXKrV6/Gz8+PwsJCrFYrgwcPJiEhwXY8KirKbt3Q3r17OXz4MP7+/nbnycvL48iRI2RnZ5ORkUGHDh1sx9zc3Lj99tuvmja7IjU1FVdXV+6+++4yx3348GEuX77MPffcY7e/oKCA2267DYCDBw/axQEQHR1d5mtc8c477zB37lyOHDlCbm4uRUVFmM1muz4NGzakfv36dtexWq2kp6fj7+/PkSNHGD58OCNGjLD1KSoqIiAgoNzxiEjFU0Ik4uS6devG/Pnz8fDwIDQ0FDc3+78WfH197bZzc3Np3749y5Ytu+pcdevWvaEYvL29yz0mNzcXgDVr1tglIlCyLqqipKSkEBsby3PPPUdMTAwBAQEsX76cV155pdyxvvXWW1claK6urhUWq4jcOCVEIk7O19eXZs2albl/u3bteOeddwgODr6qSnJFvXr1+PLLL+nSpQtQUgnZvXs37dq1K7V/VFQUVquV5ORkevbsedXxKxWq4uJi277IyEg8PT05ceLENStLERERtgXiV+zYsePXP+T/2L59O+Hh4fzlL3+x7Tt+/PhV/U6cOMHp06cJDQ21XcfFxYUWLVoQEhJCaGgo3333HbGxseW6vohUDS2qFpFyiY2NpU6dOgwYMIDPP/+co0ePsmXLFp588klOnToFwFNPPcWsWbNYuXIl33zzDX/84x+v+wyhRo0aERcXxx/+8AdWrlxpO+e7774LQHh4OCaTidWrV/PDDz+Qm5uLv78/48ePZ9y4cSxZsoQjR47w1Vdf8frrr9sWKo8aNYpDhw4xYcIE0tPTSUpKYvHixeX6vLfccgsnTpxg+fLlHDlyhLlz55a6QNzLy4u4uDj27t3L559/zpNPPsmDDz6IxWIB4LnnniMxMZG5c+fy7bffkpaWxqJFi/jrX/9arnhEpHIoIRKRcvHx8WHr1q00bNiQ+++/n4iICIYPH05eXp6tYvTMM88wZMgQ4uLiiI6Oxt/fn/vuu++6550/fz7/93//xx//+EdatmzJiBEjuHTpEgD169fnueee49lnnyUkJIQxY8YAMGPGDKZMmUJiYiIRERH07t2bNWvW0LhxY6BkXc/777/PypUradOmDQsWLGDmzJnl+rz33nsv48aNY8yYMbRt25bt27czZcqUq/o1a9aM+++/n759+9KrVy9at25td1v9448/zttvv82iRYuIiori7rvvZvHixbZYRaR6mYxrrXIUERERcRKqEImIiIjTU0IkIiIiTk8JkYiIiDg9JUQiIiLi9JQQiYiIiNNTQiQiIiJOTwmRiIiIOD0lRCIiIuL0lBCJiIiI01NCJCIiIk5PCZGIiIg4vf8PRwpRTlHsFQYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#v1.0\n",
    "#run this on the standard X_train and y train\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=24, \n",
    "                              ))])\n",
    "#make a parameter grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_features': [3500],\n",
    "    'tfidf__ngram_range': [(1, 1)],\n",
    "    'tfidf__min_df': [0.0],\n",
    "    'tfidf__max_df': [0.95],\n",
    "    'tfidf__use_idf': [True],\n",
    "    'tfidf__stop_words': [stopwords_list],\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    'clf__C': [1,],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__loss': ['squared_hinge'],\n",
    "    'clf__tol': [1e-1]}\n",
    "\n",
    "    \n",
    "#run a grid search to find the most accurate version for logistic regression\n",
    "grid_search1 = GridSearchCV(\n",
    "    pipeline1,\n",
    "    param_grid1,\n",
    "    cv=5,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,\n",
    "    verbose=0)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search1.fit(X_train_str, y_train)\n",
    "\n",
    "# Get the best train cross-validation score\n",
    "best_train_cv_score = grid_search1.best_score_\n",
    "\n",
    "# Get the best model found by grid search\n",
    "best_model = grid_search1.best_estimator_\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_model.predict(X_val_str)\n",
    "\n",
    "# Evaluate performance (accuracy) on the validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search1.best_params_\n",
    "\n",
    "print(f\"Best Train Cross-Validation Score: {best_train_cv_score:.4f}\")\n",
    "print(f\"Validation Set Accuracy: {val_accuracy:.4f}\")\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Not Positive', 'Positive']).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3ae6e-c73a-42ad-938b-24d82ceb1d03",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2e8a7522-5e1f-4eae-937d-8577a24b2ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Set Accuracy (Tuned Linear SVC Model): 0.7500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recreate the champion pipeline (Logistic Regression with stopwords)\n",
    "SVC_line = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features= 3500,\n",
    "                              ngram_range= (1, 1),\n",
    "                              min_df= 0.0,\n",
    "                              max_df= 0.95, \n",
    "                              use_idf= True,\n",
    "                              stop_words= stopwords_list,\n",
    "                              sublinear_tf= True)),\n",
    "    ('clf', LinearSVC(random_state=24,\n",
    "                      C= 1,\n",
    "                      penalty= 'l2',\n",
    "                      loss= 'squared_hinge',\n",
    "                      tol= 1e-1))])\n",
    "\n",
    "# Fit on training data\n",
    "SVC_line.fit(X_train_str, y_train)\n",
    "\n",
    "# Test set prediction\n",
    "y_test_pred_SVC = SVC_line.predict(X_test_str)\n",
    "test_accuracy_SVC = accuracy_score(y_test, y_test_pred_SVC)\n",
    "cm_test_SVC = confusion_matrix(y_test, y_test_pred_SVC)\n",
    "\n",
    "print(f\"Final Test Set Accuracy (Tuned Linear SVC Model): {test_accuracy_SVC:.4f}\")\n",
    "disp = ConfusionMatrixDisplay(cm_test_SVC, display_labels=['Not Positive', 'Positive'])\n",
    "disp.plot()\n",
    "plt.title(\"Tuned Linear SVC Model - Test Set Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812502e-481c-45cc-8418-e82841f5e985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
